{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunis, Tunisia - Data Cleaning\n",
    "##### May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic data cleaning for appropriate CSV preparation necessary for City Scan JavaScript plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory changes\n",
      "current working directory is: /Users/carolinecullinan/dev/wb/tunis-tunisia\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# change to project root directory\n",
    "os.chdir('../')\n",
    "print(\"directory changes\")\n",
    "print(f\"current working directory is:\", os.getcwd())\n",
    "\n",
    "# local imports (after changing directory)\n",
    "# from src. import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 POPULATION AND DEMOGRAPHIC TRENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATION GROWTH & DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# create data range from 2000 to 2021\n",
    "years = range(2000, 2022)\n",
    "\n",
    "# generate population growth data for Tunis, Tunisia given scan-calculations.html file\n",
    "# Note: the intention is to write the scan-calculations population growth chart data to a csv file\n",
    "# and then read it into the notebook.  In order to do this, a closer look at the 1) City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/) and demographics.py call to Oxford API; and 2)scan-calculations.html file is necesessary.  Basically, where is the scan-calculations.html file population growth data coming from, and how can we get it into a csv file?\n",
    "pop_growth = [\n",
    "    1969032 , 1984750, 2000614, 2016605, 2035590, 2070274, 2105593, 2141514,\n",
    "    2178094\t, 2215198, 2252984, 2291413, 2330547, 2370243, 2410667, 2449753, \n",
    "    2489472, 2529836, 2570854, 2612428, 2654378, 2696439\n",
    "]\n",
    "\n",
    "# create dataframe from pop_growth list\n",
    "df = pd.DataFrame({\n",
    "    'year': years,\n",
    "    'population': pop_growth\n",
    "})\n",
    "\n",
    "# save to csv (no index)\n",
    "df.to_csv('data/processed/pop_growth.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATION DISTRIBUTION BY AGE & SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate population distribution data by age and sex for Tunis, Tunisia given scan-calculations.html file\n",
    "# Note: the intention is to write the scan-calculations population growth chart data to a csv file\n",
    "# and then read it into the notebook.  In order to do this, a closer look at the 1) City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/) and demographics.py call to Oxford/WorldPop API; and 2)scan-calculations.html file is necesessary.  Basically, where is the scan-calculations.html file population growth data coming from, and how can we get it into a csv file?\n",
    "pop_age_sex = [\n",
    "    {\"ageBracket\": \"0-4\", \"sex\": \"female\", \"count\": 84255.76, \"percentage\": 0.037317174},\n",
    "    {\"ageBracket\": \"0-4\", \"sex\": \"male\", \"count\": 90688.25, \"percentage\": 0.040166147},\n",
    "    {\"ageBracket\": \"5-9\", \"sex\": \"female\", \"count\": 83410.27, \"percentage\": 0.036942703},\n",
    "    {\"ageBracket\": \"5-9\", \"sex\": \"male\", \"count\": 90365.87, \"percentage\": 0.040023362},\n",
    "    {\"ageBracket\": \"10-14\", \"sex\": \"female\", \"count\": 68791.52, \"percentage\": 0.030468006},\n",
    "    {\"ageBracket\": \"10-14\", \"sex\": \"male\", \"count\": 72744.49, \"percentage\": 0.032218791},\n",
    "    {\"ageBracket\": \"15-19\", \"sex\": \"female\", \"count\": 62009.60, \"percentage\": 0.027464272},\n",
    "    {\"ageBracket\": \"15-19\", \"sex\": \"male\", \"count\": 65126.86, \"percentage\": 0.028844915},\n",
    "    {\"ageBracket\": \"20-24\", \"sex\": \"female\", \"count\": 74367.26, \"percentage\": 0.032937522},\n",
    "    {\"ageBracket\": \"20-24\", \"sex\": \"male\", \"count\": 75255.84, \"percentage\": 0.033331078},\n",
    "    {\"ageBracket\": \"25-29\", \"sex\": \"female\", \"count\": 94742.76, \"percentage\": 0.041961902},\n",
    "    {\"ageBracket\": \"25-29\", \"sex\": \"male\", \"count\": 90570.88, \"percentage\": 0.040114164},\n",
    "    {\"ageBracket\": \"30-34\", \"sex\": \"female\", \"count\": 106160.84, \"percentage\": 0.047019010},\n",
    "    {\"ageBracket\": \"30-34\", \"sex\": \"male\", \"count\": 103540.29, \"percentage\": 0.045858363},\n",
    "    {\"ageBracket\": \"35-39\", \"sex\": \"female\", \"count\": 95786.56, \"percentage\": 0.042424208},\n",
    "    {\"ageBracket\": \"35-39\", \"sex\": \"male\", \"count\": 94503.85, \"percentage\": 0.041856091},\n",
    "    {\"ageBracket\": \"40-44\", \"sex\": \"female\", \"count\": 83400.61, \"percentage\": 0.036938427},\n",
    "    {\"ageBracket\": \"40-44\", \"sex\": \"male\", \"count\": 84275.39, \"percentage\": 0.037325869},\n",
    "    {\"ageBracket\": \"45-49\", \"sex\": \"female\", \"count\": 73773.45, \"percentage\": 0.032674520},\n",
    "    {\"ageBracket\": \"45-49\", \"sex\": \"male\", \"count\": 71356.75, \"percentage\": 0.031604158},\n",
    "    {\"ageBracket\": \"50-54\", \"sex\": \"female\", \"count\": 75568.57, \"percentage\": 0.033469589},\n",
    "    {\"ageBracket\": \"50-54\", \"sex\": \"male\", \"count\": 75557.95, \"percentage\": 0.033464882},\n",
    "    {\"ageBracket\": \"55-59\", \"sex\": \"female\", \"count\": 65577.59, \"percentage\": 0.029044548},\n",
    "    {\"ageBracket\": \"55-59\", \"sex\": \"male\", \"count\": 68573.22, \"percentage\": 0.030371323},\n",
    "    {\"ageBracket\": \"60-64\", \"sex\": \"female\", \"count\": 54934.92, \"percentage\": 0.024330870},\n",
    "    {\"ageBracket\": \"60-64\", \"sex\": \"male\", \"count\": 58307.57, \"percentage\": 0.025824630},\n",
    "    {\"ageBracket\": \"65-69\", \"sex\": \"female\", \"count\": 44470.28, \"percentage\": 0.019696046},\n",
    "    {\"ageBracket\": \"65-69\", \"sex\": \"male\", \"count\": 42850.35, \"percentage\": 0.018978570},\n",
    "    {\"ageBracket\": \"70-74\", \"sex\": \"female\", \"count\": 24648.85, \"percentage\": 0.010917065},\n",
    "    {\"ageBracket\": \"70-74\", \"sex\": \"male\", \"count\": 22636.52, \"percentage\": 0.010025793},\n",
    "    {\"ageBracket\": \"75-79\", \"sex\": \"female\", \"count\": 15277.18, \"percentage\": 0.006766316},\n",
    "    {\"ageBracket\": \"75-79\", \"sex\": \"male\", \"count\": 13950.16, \"percentage\": 0.006178577},\n",
    "    {\"ageBracket\": \"80+\", \"sex\": \"female\", \"count\": 16808.83, \"percentage\": 0.007444692},\n",
    "    {\"ageBracket\": \"80+\", \"sex\": \"male\", \"count\": 13538.88, \"percentage\": 0.005996419},\n",
    "]\n",
    "\n",
    "# convert pop_age_sex list to dataframe, pop_age_sexdf\n",
    "pop_age_sex_df = pd.DataFrame(pop_age_sex)\n",
    "\n",
    "# create output CSV of popdf for plotting\n",
    "pop_age_sex_output_df = pd.DataFrame({\n",
    "    'ageBracket': pop_age_sex_df['ageBracket'],\n",
    "    'sex': pop_age_sex_df['sex'],\n",
    "    'count': pop_age_sex_df['count'].round(2),  # round the count to 2 decimal places\n",
    "    'percentage': pop_age_sex_df['percentage'] * 100  # convert to percentage (multiply by 100)\n",
    "})\n",
    "\n",
    "# sort by age bracket and sex to ensure proper ordering\n",
    "age_order = [\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\", \"30-34\", \n",
    "             \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \n",
    "             \"65-69\", \"70-74\", \"75-79\", \"80+\"]\n",
    "\n",
    "pop_age_sex_output_df['ageBracket'] = pd.Categorical(pop_age_sex_output_df['ageBracket'], categories=age_order, ordered=True)\n",
    "pop_age_sex_output_df = pop_age_sex_output_df.sort_values(['ageBracket', 'sex'])\n",
    "\n",
    "# save pop_age_sex_output_df for pop_age_sex data to CSV\n",
    "pop_age_sex_output_df.to_csv('data/processed/pop_age_sex.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "  ageBracket     sex     count  percentage\n",
      "0        0-4  female  84255.76    3.731717\n",
      "1        0-4    male  90688.25    4.016615\n",
      "2        5-9  female  83410.27    3.694270\n",
      "3        5-9    male  90365.87    4.002336\n",
      "4      10-14  female  68791.52    3.046801\n",
      "5      10-14    male  72744.49    3.221879\n",
      "6      15-19  female  62009.60    2.746427\n",
      "7      15-19    male  65126.86    2.884491\n",
      "8      20-24  female  74367.26    3.293752\n",
      "9      20-24    male  75255.84    3.333108\n",
      "\n",
      "Total number of records: 34\n",
      "Age brackets: ['0-4', '5-9', '10-14', '15-19', '20-24', ..., '60-64', '65-69', '70-74', '75-79', '80+']\n",
      "Length: 17\n",
      "Categories (17, object): ['0-4' < '5-9' < '10-14' < '15-19' ... '65-69' < '70-74' < '75-79' < '80+']\n",
      "Sex categories: ['female' 'male']\n",
      "\n",
      "Total percentage: 100.00% (should be ~100%)\n"
     ]
    }
   ],
   "source": [
    "# pop_age_sex data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pop_age_sex_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pop_age_sex_output_df)}\")\n",
    "print(f\"Age brackets: {pop_age_sex_output_df['ageBracket'].unique()}\")\n",
    "print(f\"Sex categories: {pop_age_sex_output_df['sex'].unique()}\")\n",
    "\n",
    "# verify pop_age_sex data\n",
    "total_percentage = output_df['percentage'].sum()\n",
    "print(f\"\\nTotal percentage: {total_percentage:.2f}% (should be ~100%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 BUILT FORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN EXTENT AND CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate urban extent and change data for Tunis, Tunisia given \"tabular\" output from City Scan GCP process\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "uba = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"uba\": 166.08101814331798},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"uba\": 172.44786586480038},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"uba\": 185.11900630951914},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"uba\": 202.44611527369096},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"uba\": 209.3484337801595},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"uba\": 218.8655512133127},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"uba\": 226.97080233605266},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"uba\": 231.32775796388964},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"uba\": 235.31000915223282},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"uba\": 239.59690318203425},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"uba\": 244.28727695052265},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"uba\": 249.05396781687122},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"uba\": 253.29457114797057},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"uba\": 256.0263479213753},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"uba\": 258.9113844404829},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"uba\": 261.66818321318607},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"uba\": 264.4919158340125},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"uba\": 267.0854460612935},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"uba\": 270.3870988687197},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"uba\": 276.21722470525106},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"uba\": 281.41742170944474},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"uba\": 288.76825955333743},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"uba\": 294.66531923799204},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"uba\": 301.9654875333054},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"uba\": 310.2853023000293},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"uba\": 317.42908309972756},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"uba\": 322.2602056142696},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"uba\": 327.013134381004},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"uba\": 332.55550722560355},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"uba\": 337.01380195059915},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"uba\": 341.3507399789974}\n",
    "]\n",
    "\n",
    "# convert uba list to dataframe, uba_df\n",
    "uba_df = pd.DataFrame(uba)\n",
    "\n",
    "# create output CSV of df for plotting\n",
    "uba_output_df = pd.DataFrame({\n",
    "    'year': uba_df['year'],\n",
    "    'yearName': uba_df['yearName'],\n",
    "    'uba': uba_df['uba'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save uba_output_df for uba data to CSV\n",
    "uba_output_df.to_csv('data/processed/uba.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName     uba\n",
      "0     1     1985  166.08\n",
      "1     2     1986  172.45\n",
      "2     3     1987  185.12\n",
      "3     4     1988  202.45\n",
      "4     5     1989  209.35\n",
      "5     6     1990  218.87\n",
      "6     7     1991  226.97\n",
      "7     8     1992  231.33\n",
      "8     9     1993  235.31\n",
      "9    10     1994  239.60\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "UBA values: [166.08 172.45 185.12 202.45 209.35 218.87 226.97 231.33 235.31 239.6\n",
      " 244.29 249.05 253.29 256.03 258.91 261.67 264.49 267.09 270.39 276.22\n",
      " 281.42 288.77 294.67 301.97 310.29 317.43 322.26 327.01 332.56 337.01\n",
      " 341.35]\n"
     ]
    }
   ],
   "source": [
    "# uba data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(uba_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(uba_output_df)}\")\n",
    "print(f\"Year names: {uba_output_df['yearName'].unique()}\")\n",
    "print(f\"UBA values: {uba_output_df['uba'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAND COVER (need alternative to donut chart - do tree map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# land cover data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## This needs to be automated given the tabular-output from the GCP - hard coded for now\n",
    "\n",
    "lc = [\n",
    "      { \"lcType\": \"Tree cover\", \"pixelCount\": 385035.090196078, \"pixelTotal\": 6068006.37255, \"percentage\": 63.45},\n",
    "      { \"lcType\": \"Shrubland\", \"pixelCount\": 15153.5294117647, \"pixelTotal\": 6068006.37255, \"percentage\": 2.49},\n",
    "      { \"lcType\": \"Grassland\", \"pixelCount\": 1022591.69411765, \"pixelTotal\": 6068006.37255, \"percentage\": 16.85},\n",
    "      { \"lcType\": \"Cropland\", \"pixelCount\": 346731.71372549, \"pixelTotal\": 6068006.37255, \"percentage\": 5.71},\n",
    "      { \"lcType\": \"Built up\", \"pixelCount\": 3438092.2117647, \"pixelTotal\": 6068006.37255, \"percentage\": 56.66},\n",
    "      { \"lcType\": \"Bare sparse vegetation\", \"pixelCount\": 168537.729411765, \"pixelTotal\": 6068006.37255, \"percentage\": 2.78},\n",
    "      { \"lcType\": \"Snow and ice\", \"pixelCount\": 0, \"pixelTotal\": 6068006.37255, \"percentage\": 0},\n",
    "      { \"lcType\": \"Permanent water bodies\", \"pixelCount\": 563266.486274511, \"pixelTotal\": 6068006.37255, \"percentage\": 9.28},\n",
    "      { \"lcType\": \"Herbaceous wetland\", \"pixelCount\": 128597.917647059, \"pixelTotal\": 6068006.37255, \"percentage\": 2.12},\n",
    "      { \"lcType\": \"Mangroves\", \"pixelCount\": 0, \"pixelTotal\": 6068006.37255, \"percentage\": 0},\n",
    "      { \"lcType\": \"Moss and lichens\", \"pixelCount\": 0, \"pixelTotal\": 6068006.37255, \"percentage\": 0},\n",
    "]\n",
    "\n",
    "# convert lc list to dataframe, lc_df\n",
    "lc_df = pd.DataFrame(lc)\n",
    "\n",
    "# create output CSV of lc_df for plotting\n",
    "lc_output_df = pd.DataFrame({\n",
    "    'lcType': lc_df['lcType'],\n",
    "    'pixelCount': lc_df['pixelCount'],\n",
    "    'pixelTotal': lc_df['pixelTotal'], \n",
    "    'percentage': lc_df['percentage']\n",
    "})\n",
    "\n",
    "# save lc_output_df for lc data to CSV\n",
    "lc_output_df.to_csv('data/processed/lc.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CLIMATE CONDITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHOTOVOLTAIC POWER POTENTIAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate photovoltaic power potential data (i.e., seasonal availa bility of solar energy, plotting the \"max\" value ) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## NOTE: ov data is not available for Tunis, Tunisia (current data is just a placeholder)\n",
    "pv = [\n",
    "      { \"month\": 1, \"monthName\": \"Jan\", \"max\": 3.38, \"min\": 2.96, \"mean\": 3.09},\n",
    "      { \"month\": 2, \"monthName\": \"Feb\", \"max\": 3.39, \"min\": 3.71, \"mean\": 3.98},\n",
    "      { \"month\": 3, \"monthName\": \"Mar\", \"max\": 4.62, \"min\": 4.4, \"mean\": 4.54},\n",
    "      { \"month\": 4, \"monthName\": \"Apr\", \"max\": 4.93, \"min\": 4.66, \"mean\": 4.83},\n",
    "      { \"month\": 5, \"monthName\": \"May\", \"max\": 5.00, \"min\": 4.76, \"mean\": 4.92},\n",
    "      { \"month\": 6, \"monthName\": \"Jun\", \"max\": 5.35, \"min\": 5.16, \"mean\": 5.27},\n",
    "      { \"month\": 7, \"monthName\": \"Jul\", \"max\": 5.37, \"min\": 5.2, \"mean\": 5.29},\n",
    "      { \"month\": 8, \"monthName\": \"Aug\", \"max\": 5.2, \"min\": 5.01, \"mean\": 5.12},\n",
    "      { \"month\": 9, \"monthName\": \"Sep\", \"max\": 4.72, \"min\": 4.51, \"mean\": 4.63},\n",
    "      { \"month\": 10, \"monthName\": \"Oct\", \"max\": 4.26, \"min\": 3.96, \"mean\": 4.17},\n",
    "      { \"month\": 11, \"monthName\": \"Nov\", \"max\": 3.37, \"min\": 2.98, \"mean\": 3.29},\n",
    "      { \"month\": 12, \"monthName\": \"Dec\", \"max\": 3.19, \"min\": 2.77, \"mean\": 3.11}\n",
    "]\n",
    "\n",
    "# convert pv list to dataframe, pv_df\n",
    "pv_df = pd.DataFrame(pv)\n",
    "\n",
    "# create output CSV of pv_df for plotting\n",
    "pv_output_df = pd.DataFrame({\n",
    "    'month': pv_df['month'],\n",
    "    'monthName': pv_df['monthName'],\n",
    "    'maxPv': pv_df['max'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save pv_output_df for pv data to CSV\n",
    "pv_output_df.to_csv('data/processed/pv.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   month monthName  maxPv\n",
      "0      1       Jan   3.38\n",
      "1      2       Feb   3.39\n",
      "2      3       Mar   4.62\n",
      "3      4       Apr   4.93\n",
      "4      5       May   5.00\n",
      "5      6       Jun   5.35\n",
      "6      7       Jul   5.37\n",
      "7      8       Aug   5.20\n",
      "8      9       Sep   4.72\n",
      "9     10       Oct   4.26\n",
      "\n",
      "Total number of records: 12\n",
      "Month names: ['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec']\n",
      "PV values: [3.38 3.39 4.62 4.93 5.   5.35 5.37 5.2  4.72 4.26 3.37 3.19]\n"
     ]
    }
   ],
   "source": [
    "# pv data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pv_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pv_output_df)}\")\n",
    "print(f\"Month names: {pv_output_df['monthName'].unique()}\")\n",
    "print(f\"PV values: {pv_output_df['maxPv'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 RISK IDENTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO RIVER FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to river flooding data (i.e., built-up area exposed to fluvial flooding) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "fu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"fu\": 3.351537941381818},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"fu\": 3.4746915665244567},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"fu\": 3.6828798375989176},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"fu\": 3.9775688691902324},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"fu\": 4.116849754768217},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"fu\": 4.237071150740793},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"fu\": 4.441594135352676},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"fu\": 4.598468395951038},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"fu\": 4.801525265977889},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"fu\": 5.022908568317633},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"fu\": 5.185647287256121},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"fu\": 5.427556193786304},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"fu\": 5.631346121105671},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"fu\": 5.777957579608812},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"fu\": 6.023531772601575},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"fu\": 6.172342402982264},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"fu\": 6.3563397834037065},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"fu\": 6.53667187736257},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"fu\": 6.648829643117474},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"fu\": 6.747059320314579},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"fu\": 6.824763393321244},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"fu\": 6.928857528858474},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"fu\": 7.034417778980736},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"fu\": 7.114321023864949},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"fu\": 7.191292039579098},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"fu\": 7.28658948760614},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"fu\": 7.3327720970346295},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"fu\": 7.450061263837143},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"fu\": 7.5050405607758215},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"fu\": 7.6149991546531774},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"fu\": 7.672177623469403},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert fu list to dataframe, fu_df\n",
    "fu_df = pd.DataFrame(fu)\n",
    "\n",
    "# create output CSV of fu_df for plotting\n",
    "fu_output_df = pd.DataFrame({\n",
    "    'year': fu_df['year'],\n",
    "    'yearName': fu_df['yearName'],\n",
    "    'fu': fu_df['fu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save fu_output_df for fu data to CSV\n",
    "fu_output_df.to_csv('data/processed/fu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName    fu\n",
      "0     1     1985  3.35\n",
      "1     2     1986  3.47\n",
      "2     3     1987  3.68\n",
      "3     4     1988  3.98\n",
      "4     5     1989  4.12\n",
      "5     6     1990  4.24\n",
      "6     7     1991  4.44\n",
      "7     8     1992  4.60\n",
      "8     9     1993  4.80\n",
      "9    10     1994  5.02\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "fu values: [3.35 3.47 3.68 3.98 4.12 4.24 4.44 4.6  4.8  5.02 5.19 5.43 5.63 5.78\n",
      " 6.02 6.17 6.36 6.54 6.65 6.75 6.82 6.93 7.03 7.11 7.19 7.29 7.33 7.45\n",
      " 7.51 7.61 7.67]\n"
     ]
    }
   ],
   "source": [
    "# fu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(fu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(fu_output_df)}\")\n",
    "print(f\"Year names: {fu_output_df['yearName'].unique()}\")\n",
    "print(f\"fu values: {fu_output_df['fu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO RAINWATER FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to rainwater flooding data (i.e., built-up area exposed to pluvial flooding) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "pu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"pu\": 29.78265168032819},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"pu\": 31.410038869713063},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"pu\": 33.22875401244453},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"pu\": 34.975629540509466},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"pu\": 36.07668159386806},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"pu\": 37.00913046994804},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"pu\": 38.23993366408192},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"pu\": 39.27867584757668},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"pu\": 40.277099879983076},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"pu\": 41.435330402157895},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"pu\": 42.235095908292536},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"pu\": 43.18880344585547},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"pu\": 44.074336655214445},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"pu\": 44.960602921865934},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"pu\": 45.93630217820434},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"pu\": 46.66862641342754},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"pu\": 47.94121387323481},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"pu\": 49.155156749640824},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"pu\": 50.08247422467319},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"pu\": 50.62566967842733},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"pu\": 51.11975029358292},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"pu\": 51.73405230471108},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"pu\": 52.47737239932201},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"pu\": 53.22948918144312},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"pu\": 53.95374978644864},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"pu\": 54.567318740284286},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"pu\": 54.98369528243321},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"pu\": 55.5386196528676},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"pu\": 56.0422300128259},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"pu\": 56.627209732253434},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"pu\": 56.92336487842978},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert pu list to dataframe, pu_df\n",
    "pu_df = pd.DataFrame(pu)\n",
    "\n",
    "# create output CSV of pu_df for plotting\n",
    "pu_output_df = pd.DataFrame({\n",
    "    'year': pu_df['year'],\n",
    "    'yearName': pu_df['yearName'],\n",
    "    'pu': pu_df['pu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save pu_output_df for pu data to CSV\n",
    "pu_output_df.to_csv('data/processed/pu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName     pu\n",
      "0     1     1985  29.78\n",
      "1     2     1986  31.41\n",
      "2     3     1987  33.23\n",
      "3     4     1988  34.98\n",
      "4     5     1989  36.08\n",
      "5     6     1990  37.01\n",
      "6     7     1991  38.24\n",
      "7     8     1992  39.28\n",
      "8     9     1993  40.28\n",
      "9    10     1994  41.44\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "pu values: [29.78 31.41 33.23 34.98 36.08 37.01 38.24 39.28 40.28 41.44 42.24 43.19\n",
      " 44.07 44.96 45.94 46.67 47.94 49.16 50.08 50.63 51.12 51.73 52.48 53.23\n",
      " 53.95 54.57 54.98 55.54 56.04 56.63 56.92]\n"
     ]
    }
   ],
   "source": [
    "# pu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pu_output_df)}\")\n",
    "print(f\"Year names: {pu_output_df['yearName'].unique()}\")\n",
    "print(f\"pu values: {pu_output_df['pu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO COASTAL FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to coastal flooding data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "cu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"cu\": 2.2739437213837266},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"cu\": 2.5451749196145386},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"cu\": 2.833266435573212},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"cu\": 2.955687003423335},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"cu\": 3.063446425423144},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"cu\": 3.1396843838447777},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"cu\": 3.2349818318718198},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"cu\": 3.317084248633579},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"cu\": 3.3815932903749615},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"cu\": 3.4636957071367207},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"cu\": 3.53040392075565},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"cu\": 3.600777420837158},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"cu\": 3.6652864625785404},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"cu\": 3.7437235928777213},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"cu\": 3.811164863789166},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"cu\": 3.8639449888502972},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"cu\": 3.942382119149478},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"cu\": 4.03254816612891},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"cu\": 4.176960452754504},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"cu\": 4.2385372653258235},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"cu\": 4.319906624795067},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"cu\": 4.385881781121481},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"cu\": 4.469450312468272},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"cu\": 4.6079981407537405},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"cu\": 4.754609599256882},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"cu\": 4.844042588943799},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"cu\": 4.96499704220889},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"cu\": 5.050764745433228},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"cu\": 5.168053912235742},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"cu\": 5.225232381051967},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"cu\": 5.311733141568821},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert cu list to dataframe, cu_df\n",
    "cu_df = pd.DataFrame(cu)\n",
    "\n",
    "# create output CSV of cu_df for plotting\n",
    "cu_output_df = pd.DataFrame({\n",
    "    'year': cu_df['year'],\n",
    "    'yearName': cu_df['yearName'],\n",
    "    'cu': cu_df['cu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save cu_output_df for cu data to CSV\n",
    "cu_output_df.to_csv('data/processed/cu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName    cu\n",
      "0     1     1985  2.27\n",
      "1     2     1986  2.55\n",
      "2     3     1987  2.83\n",
      "3     4     1988  2.96\n",
      "4     5     1989  3.06\n",
      "5     6     1990  3.14\n",
      "6     7     1991  3.23\n",
      "7     8     1992  3.32\n",
      "8     9     1993  3.38\n",
      "9    10     1994  3.46\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "cu values: [2.27 2.55 2.83 2.96 3.06 3.14 3.23 3.32 3.38 3.46 3.53 3.6  3.67 3.74\n",
      " 3.81 3.86 3.94 4.03 4.18 4.24 4.32 4.39 4.47 4.61 4.75 4.84 4.96 5.05\n",
      " 5.17 5.23 5.31]\n"
     ]
    }
   ],
   "source": [
    "# cu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(cu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(cu_output_df)}\")\n",
    "print(f\"Year names: {cu_output_df['yearName'].unique()}\")\n",
    "print(f\"cu values: {cu_output_df['cu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO COMBINED RIVER, RAINWATER, AND COASTAL FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to combined flooding data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "comb = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"comb\": 32.76106345981951},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"comb\": 34.641355415122305},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"comb\": 36.74669595922742},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"comb\": 38.72814982089738},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"comb\": 39.97801250463666},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"comb\": 41.01895386000896},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"comb\": 42.41176271578881},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"comb\": 43.57512463901124},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"comb\": 44.71063038511807},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"comb\": 46.004476506408295},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"comb\": 46.92373035122299},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"comb\": 48.01525265977888},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"comb\": 49.01514280677031},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"comb\": 50.03116021419708},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"comb\": 51.17326347593655},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"comb\": 52.02727522171735},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"comb\": 53.43621133793255},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"comb\": 54.78357064157642},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"comb\": 55.887554924105075},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"comb\": 56.53850979985902},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"comb\": 57.14034983701442},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"comb\": 57.87780547328522},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"comb\": 58.721554416970804},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"comb\": 59.591693423186946},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"comb\": 60.43690848145756},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"comb\": 61.1435757114427},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"comb\": 61.66038110266628},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"comb\": 62.301073176325005},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"comb\": 62.89631569784776},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"comb\": 63.53700777150649},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"comb\": 63.918197563614655},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert comb list to dataframe, comb_df\n",
    "comb_df = pd.DataFrame(comb)\n",
    "\n",
    "# create output CSV of comb_df for plotting\n",
    "comb_output_df = pd.DataFrame({\n",
    "    'year': comb_df['year'],\n",
    "    'yearName': comb_df['yearName'],\n",
    "    'comb': comb_df['comb'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save comb_output_df for comb data to CSV\n",
    "comb_output_df.to_csv('data/processed/comb.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName   comb\n",
      "0     1     1985  32.76\n",
      "1     2     1986  34.64\n",
      "2     3     1987  36.75\n",
      "3     4     1988  38.73\n",
      "4     5     1989  39.98\n",
      "5     6     1990  41.02\n",
      "6     7     1991  42.41\n",
      "7     8     1992  43.58\n",
      "8     9     1993  44.71\n",
      "9    10     1994  46.00\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "comb values: [32.76 34.64 36.75 38.73 39.98 41.02 42.41 43.58 44.71 46.   46.92 48.02\n",
      " 49.02 50.03 51.17 52.03 53.44 54.78 55.89 56.54 57.14 57.88 58.72 59.59\n",
      " 60.44 61.14 61.66 62.3  62.9  63.54 63.92]\n"
     ]
    }
   ],
   "source": [
    "# comb data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(comb_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(comb_output_df)}\")\n",
    "print(f\"Year names: {comb_output_df['yearName'].unique()}\")\n",
    "print(f\"comb values: {comb_output_df['comb'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELEVATION (need alternative to donut chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# elevation data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## This needs to be automated given the tabular-output from the GCP - hard coded for now\n",
    "\n",
    "elevation = [\n",
    "      { \"bin\": \"-5-40m\", \"count\": 413599, \"total\": 549697, \"percentage\": 75.24},\n",
    "      { \"bin\": \"40-90m\", \"count\": 94379, \"total\": 549697, \"percentage\": 17.17 },\n",
    "      { \"bin\": \"90-135m\", \"count\": 32786 , \"total\": 549697, \"percentage\": 5.96 },\n",
    "      { \"bin\": \"135-185m\", \"count\": 8043, \"total\": 549697, \"percentage\": 1.46 },\n",
    "      { \"bin\": \"135-235\", \"count\": 890, \"total\": 549697, \"percentage\": 0.16 },\n",
    "]\n",
    "\n",
    "# convert elevation list to dataframe, elevation_df\n",
    "elevation_df = pd.DataFrame(elevation)\n",
    "\n",
    "# create output CSV of elevation_df for plotting\n",
    "elevation_output_df = pd.DataFrame({\n",
    "    'bin': elevation_df['bin'],\n",
    "    'count': elevation_df['count'],\n",
    "    'total': elevation_df['total'], \n",
    "    'percentage': elevation_df['percentage']\n",
    "})\n",
    "\n",
    "# save elevation_output_df for elevation data to CSV\n",
    "elevation_output_df.to_csv('data/processed/elevation.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLOPE (need alternative to donut chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# slope data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## This needs to be automated given the tabular-output from the GCP - hard coded for now\n",
    "\n",
    "slope = [\n",
    "      { \"bin\": \"0-2\", \"count\": 428343, \"total\": 549702, \"percentage\": 77.92 },\n",
    "      { \"bin\": \"2-5\", \"count\": 79034, \"total\": 549702, \"percentage\": 14.38 },\n",
    "      { \"bin\": \"5-10\", \"count\": 31121, \"total\": 549702, \"percentage\": 5.66 },\n",
    "      { \"bin\": \"10-20\", \"count\": 10147, \"total\": 549702, \"percentage\": 1.85 },\n",
    "      { \"bin\": \"20+\", \"count\": 1057, \"total\": 549702, \"percentage\": 0.19 },\n",
    "]\n",
    "\n",
    "# convert slope list to dataframe, slope_df\n",
    "slope_df = pd.DataFrame(slope)\n",
    "\n",
    "# create output CSV of slope_df for plotting\n",
    "slope_output_df = pd.DataFrame({\n",
    "    'bin': slope_df['bin'],\n",
    "    'count': slope_df['count'],\n",
    "    'total': slope_df['total'], \n",
    "    'percentage': slope_df['percentage']\n",
    "})\n",
    "\n",
    "# save slope_output_df for slope data to CSV\n",
    "slope_output_df.to_csv('data/processed/slope.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HISTORICAL BURNT AREA & FIRE WEATHER INDEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate historical burnt area & fire weather index data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "fwi = [\n",
    "      { \"week\": 1, \"monthName\": \"Jan\", \"fwi\": 36.03855628967285},\n",
    "      { \"week\": 2, \"monthName\": \"Jan\", \"fwi\": 28.35186767578125},\n",
    "      { \"week\": 3, \"monthName\": \"Jan\", \"fwi\": 34.48613758087156},\n",
    "      { \"week\": 4, \"monthName\": \"Jan\", \"fwi\": 35.160119628906244},\n",
    "      { \"week\": 5, \"monthName\": \"Feb\", \"fwi\": 41.2155460357666},\n",
    "      { \"week\": 6, \"monthName\": \"Feb\", \"fwi\": 42.91906299591064},\n",
    "      { \"week\": 7, \"monthName\": \"Feb\", \"fwi\": 40.35708732604981},\n",
    "      { \"week\": 8, \"monthName\": \"Feb\", \"fwi\": 35.13482322692871},\n",
    "      { \"week\": 9, \"monthName\": \"Feb\", \"fwi\": 43.7328405380249},\n",
    "      { \"week\": 10, \"monthName\": \"Mar\", \"fwi\": 55.629536437988264},\n",
    "      { \"week\": 11, \"monthName\": \"Mar\", \"fwi\": 51.963145637512206},\n",
    "      { \"week\": 12, \"monthName\": \"Mar\", \"fwi\": 48.64410858154295},\n",
    "      { \"week\": 13, \"monthName\": \"Mar\", \"fwi\": 48.45940856933592},\n",
    "      { \"week\": 14, \"monthName\": \"Apr\", \"fwi\": 42.525428390502924},\n",
    "      { \"week\": 15, \"monthName\": \"Apr\", \"fwi\": 48.989934921264634},\n",
    "      { \"week\": 16, \"monthName\": \"Apr\", \"fwi\": 47.94815864562989},\n",
    "      { \"week\": 17, \"monthName\": \"Apr\", \"fwi\": 59.693392562866215},\n",
    "      { \"week\": 18, \"monthName\": \"May\", \"fwi\": 53.26485347747803},\n",
    "      { \"week\": 19, \"monthName\": \"May\", \"fwi\": 67.04015121459962},\n",
    "      { \"week\": 20, \"monthName\": \"May\", \"fwi\": 66.2925880432129},\n",
    "      { \"week\": 21, \"monthName\": \"May\", \"fwi\": 63.51103172302246},\n",
    "      { \"week\": 22, \"monthName\": \"May\", \"fwi\": 57.59551124572754},\n",
    "      { \"week\": 23, \"monthName\": \"Jun\", \"fwi\": 66.97727813720704},\n",
    "      { \"week\": 24, \"monthName\": \"Jun\", \"fwi\": 75.7531303405762},\n",
    "      { \"week\": 25, \"monthName\": \"Jun\", \"fwi\": 80.30134506225586},\n",
    "      { \"week\": 26, \"monthName\": \"Jun\", \"fwi\": 90.69736862182619},\n",
    "      { \"week\": 27, \"monthName\": \"Jul\", \"fwi\": 75.26012268066407},\n",
    "      { \"week\": 28, \"monthName\": \"Jul\", \"fwi\": 95.59054870605469},\n",
    "      { \"week\": 29, \"monthName\": \"Jul\", \"fwi\": 82.06852722167967},\n",
    "      { \"week\": 30, \"monthName\": \"Jul\", \"fwi\": 81.8968620300293},\n",
    "      { \"week\": 31, \"monthName\": \"Aug\", \"fwi\": 81.7047821044922},\n",
    "      { \"week\": 32, \"monthName\": \"Aug\", \"fwi\": 81.58447265625001}, \n",
    "      { \"week\": 33, \"monthName\": \"Aug\", \"fwi\": 65.29224243164063},  \n",
    "      { \"week\": 34, \"monthName\": \"Aug\", \"fwi\": 67.29769515991212},  \n",
    "      { \"week\": 35, \"monthName\": \"Aug\", \"fwi\": 64.21281738281252},  \n",
    "      { \"week\": 36, \"monthName\": \"Sep\", \"fwi\": 69.20558013916019},  \n",
    "      { \"week\": 37, \"monthName\": \"Sep\", \"fwi\": 59.376176834106474},  \n",
    "      { \"week\": 38, \"monthName\": \"Sep\", \"fwi\": 50.01441955566406},  \n",
    "      { \"week\": 39, \"monthName\": \"Sep\", \"fwi\": 40.38814010620118 },  \n",
    "      { \"week\": 40, \"monthName\": \"Oct\", \"fwi\": 48.369334793090815},  \n",
    "      { \"week\": 41, \"monthName\": \"Oct\", \"fwi\": 43.82190437316895},  \n",
    "      { \"week\": 42, \"monthName\": \"Oct\", \"fwi\": 37.03949813842773},  \n",
    "      { \"week\": 43, \"monthName\": \"Oct\", \"fwi\": 50.04811096191406},  \n",
    "      { \"week\": 44, \"monthName\": \"Nov\", \"fwi\": 47.38101158142093},  \n",
    "      { \"week\": 45, \"monthName\": \"Nov\", \"fwi\": 37.50416679382325},  \n",
    "      { \"week\": 46, \"monthName\": \"Nov\", \"fwi\": 29.76080322265625},  \n",
    "      { \"week\": 47, \"monthName\": \"Nov\", \"fwi\": 36.063685607910124},  \n",
    "      { \"week\": 48, \"monthName\": \"Nov\", \"fwi\": 34.42437210083008},  \n",
    "      { \"week\": 49, \"monthName\": \"Dec\", \"fwi\": 32.008924865722626},  \n",
    "      { \"week\": 50, \"monthName\": \"Dec\", \"fwi\": 33.579549407958986},  \n",
    "      { \"week\": 51, \"monthName\": \"Dec\", \"fwi\": 31.927024841308594},  \n",
    "      { \"week\": 52, \"monthName\": \"Dec\", \"fwi\": 34.5278169631958},  \n",
    "      { \"week\": 53, \"monthName\": \"Dec\", \"fwi\": 31.089004516601562}  \n",
    "\n",
    "]\n",
    "\n",
    "# convert fwi list to dataframe, fwi_df\n",
    "fwi_df = pd.DataFrame(fwi)\n",
    "\n",
    "# create output CSV of fwi_df for plotting\n",
    "fwi_output_df = pd.DataFrame({\n",
    "    'week': fwi_df['week'],\n",
    "    'monthName': fwi_df['monthName'],\n",
    "    'fwi': fwi_df['fwi'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save fwi_output_df for fwi data to CSV\n",
    "fwi_output_df.to_csv('data/processed/fwi.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   week monthName    fwi\n",
      "0     1       Jan  36.04\n",
      "1     2       Jan  28.35\n",
      "2     3       Jan  34.49\n",
      "3     4       Jan  35.16\n",
      "4     5       Feb  41.22\n",
      "5     6       Feb  42.92\n",
      "6     7       Feb  40.36\n",
      "7     8       Feb  35.13\n",
      "8     9       Feb  43.73\n",
      "9    10       Mar  55.63\n",
      "\n",
      "Total number of records: 53\n",
      "Month names: ['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec']\n",
      "fwi values: [36.04 28.35 34.49 35.16 41.22 42.92 40.36 35.13 43.73 55.63 51.96 48.64\n",
      " 48.46 42.53 48.99 47.95 59.69 53.26 67.04 66.29 63.51 57.6  66.98 75.75\n",
      " 80.3  90.7  75.26 95.59 82.07 81.9  81.7  81.58 65.29 67.3  64.21 69.21\n",
      " 59.38 50.01 40.39 48.37 43.82 37.04 50.05 47.38 37.5  29.76 36.06 34.42\n",
      " 32.01 33.58 31.93 34.53 31.09]\n"
     ]
    }
   ],
   "source": [
    "# fwi data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(fwi_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(fwi_output_df)}\")\n",
    "print(f\"Month names: {fwi_output_df['monthName'].unique()}\")\n",
    "print(f\"fwi values: {fwi_output_df['fwi'].unique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
