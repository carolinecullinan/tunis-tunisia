{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunis, Tunisia - Data Cleaning\n",
    "##### May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic data cleaning for appropriate CSV preparation necessary for City Scan JavaScript plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory changes\n",
      "current working directory is: /Users/carolinecullinan/dev/wb/tunis-tunisia\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# change to project root directory\n",
    "os.chdir('../')\n",
    "print(\"directory changes\")\n",
    "print(f\"current working directory is:\", os.getcwd())\n",
    "\n",
    "# local imports (after changing directory)\n",
    "# from src. import "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 POPULATION AND DEMOGRAPHIC TRENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATION GROWTH & DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# create data range from 2000 to 2021\n",
    "years = range(2000, 2022)\n",
    "\n",
    "# generate population growth data for Tunis, Tunisia given scan-calculations.html file\n",
    "# Note: the intention is to write the scan-calculations population growth chart data to a csv file\n",
    "# and then read it into the notebook.  In order to do this, a closer look at the 1) City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/) and demographics.py call to Oxford API; and 2)scan-calculations.html file is necesessary.  Basically, where is the scan-calculations.html file population growth data coming from, and how can we get it into a csv file?\n",
    "pop_growth = [\n",
    "    1969032 , 1984750, 2000614, 2016605, 2035590, 2070274, 2105593, 2141514,\n",
    "    2178094\t, 2215198, 2252984, 2291413, 2330547, 2370243, 2410667, 2449753, \n",
    "    2489472, 2529836, 2570854, 2612428, 2654378, 2696439\n",
    "]\n",
    "\n",
    "# create dataframe from pop_growth list\n",
    "df = pd.DataFrame({\n",
    "    'year': years,\n",
    "    'population': pop_growth\n",
    "})\n",
    "\n",
    "# save to csv (no index)\n",
    "df.to_csv('data/processed/pop_growth.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATION DISTRIBUTION BY AGE & SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate population distribution data by age and sex for Tunis, Tunisia given scan-calculations.html file\n",
    "# Note: the intention is to write the scan-calculations population growth chart data to a csv file\n",
    "# and then read it into the notebook.  In order to do this, a closer look at the 1) City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/) and demographics.py call to Oxford/WorldPop API; and 2)scan-calculations.html file is necesessary.  Basically, where is the scan-calculations.html file population growth data coming from, and how can we get it into a csv file?\n",
    "pop_age_sex = [\n",
    "    {\"ageBracket\": \"0-4\", \"sex\": \"female\", \"count\": 84255.76, \"percentage\": 0.037317174},\n",
    "    {\"ageBracket\": \"0-4\", \"sex\": \"male\", \"count\": 90688.25, \"percentage\": 0.040166147},\n",
    "    {\"ageBracket\": \"5-9\", \"sex\": \"female\", \"count\": 83410.27, \"percentage\": 0.036942703},\n",
    "    {\"ageBracket\": \"5-9\", \"sex\": \"male\", \"count\": 90365.87, \"percentage\": 0.040023362},\n",
    "    {\"ageBracket\": \"10-14\", \"sex\": \"female\", \"count\": 68791.52, \"percentage\": 0.030468006},\n",
    "    {\"ageBracket\": \"10-14\", \"sex\": \"male\", \"count\": 72744.49, \"percentage\": 0.032218791},\n",
    "    {\"ageBracket\": \"15-19\", \"sex\": \"female\", \"count\": 62009.60, \"percentage\": 0.027464272},\n",
    "    {\"ageBracket\": \"15-19\", \"sex\": \"male\", \"count\": 65126.86, \"percentage\": 0.028844915},\n",
    "    {\"ageBracket\": \"20-24\", \"sex\": \"female\", \"count\": 74367.26, \"percentage\": 0.032937522},\n",
    "    {\"ageBracket\": \"20-24\", \"sex\": \"male\", \"count\": 75255.84, \"percentage\": 0.033331078},\n",
    "    {\"ageBracket\": \"25-29\", \"sex\": \"female\", \"count\": 94742.76, \"percentage\": 0.041961902},\n",
    "    {\"ageBracket\": \"25-29\", \"sex\": \"male\", \"count\": 90570.88, \"percentage\": 0.040114164},\n",
    "    {\"ageBracket\": \"30-34\", \"sex\": \"female\", \"count\": 106160.84, \"percentage\": 0.047019010},\n",
    "    {\"ageBracket\": \"30-34\", \"sex\": \"male\", \"count\": 103540.29, \"percentage\": 0.045858363},\n",
    "    {\"ageBracket\": \"35-39\", \"sex\": \"female\", \"count\": 95786.56, \"percentage\": 0.042424208},\n",
    "    {\"ageBracket\": \"35-39\", \"sex\": \"male\", \"count\": 94503.85, \"percentage\": 0.041856091},\n",
    "    {\"ageBracket\": \"40-44\", \"sex\": \"female\", \"count\": 83400.61, \"percentage\": 0.036938427},\n",
    "    {\"ageBracket\": \"40-44\", \"sex\": \"male\", \"count\": 84275.39, \"percentage\": 0.037325869},\n",
    "    {\"ageBracket\": \"45-49\", \"sex\": \"female\", \"count\": 73773.45, \"percentage\": 0.032674520},\n",
    "    {\"ageBracket\": \"45-49\", \"sex\": \"male\", \"count\": 71356.75, \"percentage\": 0.031604158},\n",
    "    {\"ageBracket\": \"50-54\", \"sex\": \"female\", \"count\": 75568.57, \"percentage\": 0.033469589},\n",
    "    {\"ageBracket\": \"50-54\", \"sex\": \"male\", \"count\": 75557.95, \"percentage\": 0.033464882},\n",
    "    {\"ageBracket\": \"55-59\", \"sex\": \"female\", \"count\": 65577.59, \"percentage\": 0.029044548},\n",
    "    {\"ageBracket\": \"55-59\", \"sex\": \"male\", \"count\": 68573.22, \"percentage\": 0.030371323},\n",
    "    {\"ageBracket\": \"60-64\", \"sex\": \"female\", \"count\": 54934.92, \"percentage\": 0.024330870},\n",
    "    {\"ageBracket\": \"60-64\", \"sex\": \"male\", \"count\": 58307.57, \"percentage\": 0.025824630},\n",
    "    {\"ageBracket\": \"65-69\", \"sex\": \"female\", \"count\": 44470.28, \"percentage\": 0.019696046},\n",
    "    {\"ageBracket\": \"65-69\", \"sex\": \"male\", \"count\": 42850.35, \"percentage\": 0.018978570},\n",
    "    {\"ageBracket\": \"70-74\", \"sex\": \"female\", \"count\": 24648.85, \"percentage\": 0.010917065},\n",
    "    {\"ageBracket\": \"70-74\", \"sex\": \"male\", \"count\": 22636.52, \"percentage\": 0.010025793},\n",
    "    {\"ageBracket\": \"75-79\", \"sex\": \"female\", \"count\": 15277.18, \"percentage\": 0.006766316},\n",
    "    {\"ageBracket\": \"75-79\", \"sex\": \"male\", \"count\": 13950.16, \"percentage\": 0.006178577},\n",
    "    {\"ageBracket\": \"80+\", \"sex\": \"female\", \"count\": 16808.83, \"percentage\": 0.007444692},\n",
    "    {\"ageBracket\": \"80+\", \"sex\": \"male\", \"count\": 13538.88, \"percentage\": 0.005996419},\n",
    "]\n",
    "\n",
    "# convert pop_age_sex list to dataframe, pop_age_sexdf\n",
    "pop_age_sex_df = pd.DataFrame(pop_age_sex)\n",
    "\n",
    "# create output CSV of popdf for plotting\n",
    "pop_age_sex_output_df = pd.DataFrame({\n",
    "    'ageBracket': pop_age_sex_df['ageBracket'],\n",
    "    'sex': pop_age_sex_df['sex'],\n",
    "    'count': pop_age_sex_df['count'].round(2),  # round the count to 2 decimal places\n",
    "    'percentage': pop_age_sex_df['percentage'] * 100  # convert to percentage (multiply by 100)\n",
    "})\n",
    "\n",
    "# sort by age bracket and sex to ensure proper ordering\n",
    "age_order = [\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\", \"30-34\", \n",
    "             \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \n",
    "             \"65-69\", \"70-74\", \"75-79\", \"80+\"]\n",
    "\n",
    "pop_age_sex_output_df['ageBracket'] = pd.Categorical(pop_age_sex_output_df['ageBracket'], categories=age_order, ordered=True)\n",
    "pop_age_sex_output_df = pop_age_sex_output_df.sort_values(['ageBracket', 'sex'])\n",
    "\n",
    "# save pop_age_sex_output_df for pop_age_sex data to CSV\n",
    "pop_age_sex_output_df.to_csv('data/processed/pop_age_sex.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "  ageBracket     sex     count  percentage\n",
      "0        0-4  female  84255.76    3.731717\n",
      "1        0-4    male  90688.25    4.016615\n",
      "2        5-9  female  83410.27    3.694270\n",
      "3        5-9    male  90365.87    4.002336\n",
      "4      10-14  female  68791.52    3.046801\n",
      "5      10-14    male  72744.49    3.221879\n",
      "6      15-19  female  62009.60    2.746427\n",
      "7      15-19    male  65126.86    2.884491\n",
      "8      20-24  female  74367.26    3.293752\n",
      "9      20-24    male  75255.84    3.333108\n",
      "\n",
      "Total number of records: 34\n",
      "Age brackets: ['0-4', '5-9', '10-14', '15-19', '20-24', ..., '60-64', '65-69', '70-74', '75-79', '80+']\n",
      "Length: 17\n",
      "Categories (17, object): ['0-4' < '5-9' < '10-14' < '15-19' ... '65-69' < '70-74' < '75-79' < '80+']\n",
      "Sex categories: ['female' 'male']\n",
      "\n",
      "Total percentage: 100.00% (should be ~100%)\n"
     ]
    }
   ],
   "source": [
    "# pop_age_sex data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pop_age_sex_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pop_age_sex_output_df)}\")\n",
    "print(f\"Age brackets: {pop_age_sex_output_df['ageBracket'].unique()}\")\n",
    "print(f\"Sex categories: {pop_age_sex_output_df['sex'].unique()}\")\n",
    "\n",
    "# verify pop_age_sex data\n",
    "total_percentage = output_df['percentage'].sum()\n",
    "print(f\"\\nTotal percentage: {total_percentage:.2f}% (should be ~100%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 BUILT FORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN EXTENT AND CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate urban extent and change data for Tunis, Tunisia given \"tabular\" output from City Scan GCP process\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "uba = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"uba\": 166.08101814331798},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"uba\": 172.44786586480038},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"uba\": 185.11900630951914},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"uba\": 202.44611527369096},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"uba\": 209.3484337801595},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"uba\": 218.8655512133127},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"uba\": 226.97080233605266},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"uba\": 231.32775796388964},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"uba\": 235.31000915223282},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"uba\": 239.59690318203425},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"uba\": 244.28727695052265},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"uba\": 249.05396781687122},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"uba\": 253.29457114797057},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"uba\": 256.0263479213753},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"uba\": 258.9113844404829},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"uba\": 261.66818321318607},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"uba\": 264.4919158340125},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"uba\": 267.0854460612935},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"uba\": 270.3870988687197},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"uba\": 276.21722470525106},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"uba\": 281.41742170944474},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"uba\": 288.76825955333743},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"uba\": 294.66531923799204},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"uba\": 301.9654875333054},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"uba\": 310.2853023000293},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"uba\": 317.42908309972756},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"uba\": 322.2602056142696},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"uba\": 327.013134381004},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"uba\": 332.55550722560355},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"uba\": 337.01380195059915},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"uba\": 341.3507399789974}\n",
    "]\n",
    "\n",
    "# convert uba list to dataframe, uba_df\n",
    "uba_df = pd.DataFrame(uba)\n",
    "\n",
    "# create output CSV of df for plotting\n",
    "uba_output_df = pd.DataFrame({\n",
    "    'year': uba_df['year'],\n",
    "    'yearName': uba_df['yearName'],\n",
    "    'uba': uba_df['uba'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save uba_output_df for uba data to CSV\n",
    "uba_output_df.to_csv('data/processed/uba.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName     uba\n",
      "0     1     1985  166.08\n",
      "1     2     1986  172.45\n",
      "2     3     1987  185.12\n",
      "3     4     1988  202.45\n",
      "4     5     1989  209.35\n",
      "5     6     1990  218.87\n",
      "6     7     1991  226.97\n",
      "7     8     1992  231.33\n",
      "8     9     1993  235.31\n",
      "9    10     1994  239.60\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "UBA values: [166.08 172.45 185.12 202.45 209.35 218.87 226.97 231.33 235.31 239.6\n",
      " 244.29 249.05 253.29 256.03 258.91 261.67 264.49 267.09 270.39 276.22\n",
      " 281.42 288.77 294.67 301.97 310.29 317.43 322.26 327.01 332.56 337.01\n",
      " 341.35]\n"
     ]
    }
   ],
   "source": [
    "# uba data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(uba_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(uba_output_df)}\")\n",
    "print(f\"Year names: {uba_output_df['yearName'].unique()}\")\n",
    "print(f\"UBA values: {uba_output_df['uba'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAND COVER (need alternative to donut chart - do tree map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 CLIMATE CONDITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHOTOVOLTAIC POWER POTENTIAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate photovoltaic power potential data (i.e., seasonal availa bility of solar energy, plotting the \"max\" value ) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## NOTE: ov data is not available for Tunis, Tunisia (current data is just a placeholder)\n",
    "pv = [\n",
    "      { \"month\": 1, \"monthName\": \"Jan\", \"max\": 3.38, \"min\": 2.96, \"mean\": 3.09},\n",
    "      { \"month\": 2, \"monthName\": \"Feb\", \"max\": 3.39, \"min\": 3.71, \"mean\": 3.98},\n",
    "      { \"month\": 3, \"monthName\": \"Mar\", \"max\": 4.62, \"min\": 4.4, \"mean\": 4.54},\n",
    "      { \"month\": 4, \"monthName\": \"Apr\", \"max\": 4.93, \"min\": 4.66, \"mean\": 4.83},\n",
    "      { \"month\": 5, \"monthName\": \"May\", \"max\": 5.00, \"min\": 4.76, \"mean\": 4.92},\n",
    "      { \"month\": 6, \"monthName\": \"Jun\", \"max\": 5.35, \"min\": 5.16, \"mean\": 5.27},\n",
    "      { \"month\": 7, \"monthName\": \"Jul\", \"max\": 5.37, \"min\": 5.2, \"mean\": 5.29},\n",
    "      { \"month\": 8, \"monthName\": \"Aug\", \"max\": 5.2, \"min\": 5.01, \"mean\": 5.12},\n",
    "      { \"month\": 9, \"monthName\": \"Sep\", \"max\": 4.72, \"min\": 4.51, \"mean\": 4.63},\n",
    "      { \"month\": 10, \"monthName\": \"Oct\", \"max\": 4.26, \"min\": 3.96, \"mean\": 4.17},\n",
    "      { \"month\": 11, \"monthName\": \"Nov\", \"max\": 3.37, \"min\": 2.98, \"mean\": 3.29},\n",
    "      { \"month\": 12, \"monthName\": \"Dec\", \"max\": 3.19, \"min\": 2.77, \"mean\": 3.11}\n",
    "]\n",
    "\n",
    "# convert pv list to dataframe, pv_df\n",
    "pv_df = pd.DataFrame(pv)\n",
    "\n",
    "# create output CSV of pv_df for plotting\n",
    "pv_output_df = pd.DataFrame({\n",
    "    'month': pv_df['month'],\n",
    "    'monthName': pv_df['monthName'],\n",
    "    'maxPv': pv_df['max'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save pv_output_df for pv data to CSV\n",
    "pv_output_df.to_csv('data/processed/pv.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   month monthName  maxPv\n",
      "0      1       Jan   3.38\n",
      "1      2       Feb   3.39\n",
      "2      3       Mar   4.62\n",
      "3      4       Apr   4.93\n",
      "4      5       May   5.00\n",
      "5      6       Jun   5.35\n",
      "6      7       Jul   5.37\n",
      "7      8       Aug   5.20\n",
      "8      9       Sep   4.72\n",
      "9     10       Oct   4.26\n",
      "\n",
      "Total number of records: 12\n",
      "Month names: ['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec']\n",
      "PV values: [3.38 3.39 4.62 4.93 5.   5.35 5.37 5.2  4.72 4.26 3.37 3.19]\n"
     ]
    }
   ],
   "source": [
    "# pv data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pv_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pv_output_df)}\")\n",
    "print(f\"Month names: {pv_output_df['monthName'].unique()}\")\n",
    "print(f\"PV values: {pv_output_df['maxPv'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 RISK IDENTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO RIVER FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to river flooding data (i.e., built-up area exposed to fluvial flooding) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "fu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"fu\": 3.351537941381818},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"fu\": 3.4746915665244567},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"fu\": 3.6828798375989176},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"fu\": 3.9775688691902324},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"fu\": 4.116849754768217},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"fu\": 4.237071150740793},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"fu\": 4.441594135352676},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"fu\": 4.598468395951038},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"fu\": 4.801525265977889},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"fu\": 5.022908568317633},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"fu\": 5.185647287256121},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"fu\": 5.427556193786304},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"fu\": 5.631346121105671},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"fu\": 5.777957579608812},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"fu\": 6.023531772601575},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"fu\": 6.172342402982264},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"fu\": 6.3563397834037065},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"fu\": 6.53667187736257},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"fu\": 6.648829643117474},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"fu\": 6.747059320314579},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"fu\": 6.824763393321244},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"fu\": 6.928857528858474},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"fu\": 7.034417778980736},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"fu\": 7.114321023864949},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"fu\": 7.191292039579098},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"fu\": 7.28658948760614},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"fu\": 7.3327720970346295},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"fu\": 7.450061263837143},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"fu\": 7.5050405607758215},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"fu\": 7.6149991546531774},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"fu\": 7.672177623469403},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert fu list to dataframe, fu_df\n",
    "fu_df = pd.DataFrame(fu)\n",
    "\n",
    "# create output CSV of fu_df for plotting\n",
    "fu_output_df = pd.DataFrame({\n",
    "    'year': fu_df['year'],\n",
    "    'yearName': fu_df['yearName'],\n",
    "    'fu': fu_df['fu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save fu_output_df for fu data to CSV\n",
    "fu_output_df.to_csv('data/processed/fu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName    fu\n",
      "0     1     1985  3.35\n",
      "1     2     1986  3.47\n",
      "2     3     1987  3.68\n",
      "3     4     1988  3.98\n",
      "4     5     1989  4.12\n",
      "5     6     1990  4.24\n",
      "6     7     1991  4.44\n",
      "7     8     1992  4.60\n",
      "8     9     1993  4.80\n",
      "9    10     1994  5.02\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "fu values: [3.35 3.47 3.68 3.98 4.12 4.24 4.44 4.6  4.8  5.02 5.19 5.43 5.63 5.78\n",
      " 6.02 6.17 6.36 6.54 6.65 6.75 6.82 6.93 7.03 7.11 7.19 7.29 7.33 7.45\n",
      " 7.51 7.61 7.67]\n"
     ]
    }
   ],
   "source": [
    "# fu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(fu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(fu_output_df)}\")\n",
    "print(f\"Year names: {fu_output_df['yearName'].unique()}\")\n",
    "print(f\"fu values: {fu_output_df['fu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO RAINWATER FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to rainwater flooding data (i.e., built-up area exposed to pluvial flooding) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "pu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"pu\": 29.78265168032819},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"pu\": 31.410038869713063},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"pu\": 33.22875401244453},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"pu\": 34.975629540509466},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"pu\": 36.07668159386806},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"pu\": 37.00913046994804},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"pu\": 38.23993366408192},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"pu\": 39.27867584757668},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"pu\": 40.277099879983076},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"pu\": 41.435330402157895},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"pu\": 42.235095908292536},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"pu\": 43.18880344585547},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"pu\": 44.074336655214445},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"pu\": 44.960602921865934},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"pu\": 45.93630217820434},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"pu\": 46.66862641342754},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"pu\": 47.94121387323481},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"pu\": 49.155156749640824},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"pu\": 50.08247422467319},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"pu\": 50.62566967842733},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"pu\": 51.11975029358292},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"pu\": 51.73405230471108},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"pu\": 52.47737239932201},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"pu\": 53.22948918144312},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"pu\": 53.95374978644864},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"pu\": 54.567318740284286},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"pu\": 54.98369528243321},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"pu\": 55.5386196528676},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"pu\": 56.0422300128259},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"pu\": 56.627209732253434},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"pu\": 56.92336487842978},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert pu list to dataframe, pu_df\n",
    "pu_df = pd.DataFrame(pu)\n",
    "\n",
    "# create output CSV of pu_df for plotting\n",
    "pu_output_df = pd.DataFrame({\n",
    "    'year': pu_df['year'],\n",
    "    'yearName': pu_df['yearName'],\n",
    "    'pu': pu_df['pu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save pu_output_df for pu data to CSV\n",
    "pu_output_df.to_csv('data/processed/pu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName     pu\n",
      "0     1     1985  29.78\n",
      "1     2     1986  31.41\n",
      "2     3     1987  33.23\n",
      "3     4     1988  34.98\n",
      "4     5     1989  36.08\n",
      "5     6     1990  37.01\n",
      "6     7     1991  38.24\n",
      "7     8     1992  39.28\n",
      "8     9     1993  40.28\n",
      "9    10     1994  41.44\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "pu values: [29.78 31.41 33.23 34.98 36.08 37.01 38.24 39.28 40.28 41.44 42.24 43.19\n",
      " 44.07 44.96 45.94 46.67 47.94 49.16 50.08 50.63 51.12 51.73 52.48 53.23\n",
      " 53.95 54.57 54.98 55.54 56.04 56.63 56.92]\n"
     ]
    }
   ],
   "source": [
    "# pu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pu_output_df)}\")\n",
    "print(f\"Year names: {pu_output_df['yearName'].unique()}\")\n",
    "print(f\"pu values: {pu_output_df['pu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO COASTAL FLOODING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO COMBINED RIVER, RAINWATER, AND COASTAL FLOODING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELEVATION (need alternative to donut chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLOPE (need alternative to donut chart)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HISTORICAL BURNT AREA & FIRE WEATHER INDEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
