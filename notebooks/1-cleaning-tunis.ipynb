{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tunis, Tunisia - Data Cleaning\n",
    "##### May 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic data cleaning for appropriate CSV preparation necessary for City Scan JavaScript plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "directory changes\n",
      "current working directory is: /Users/carolinecullinan/dev/wb/tunis-tunisia\n"
     ]
    }
   ],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "# third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# change to project root directory\n",
    "os.chdir('../')\n",
    "print(\"directory changes\")\n",
    "print(f\"current working directory is:\", os.getcwd())\n",
    "\n",
    "# local imports (after changing directory)\n",
    "from src.lc_cleanup import clean_land_cover_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 POPULATION AND DEMOGRAPHIC TRENDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATION GROWTH & DENSITY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# create data range from 2000 to 2021\n",
    "years = range(2000, 2022)\n",
    "\n",
    "# generate population growth data for Tunis, Tunisia given scan-calculations.html file\n",
    "# Note: the intention is to write the scan-calculations population growth chart data to a csv file\n",
    "# and then read it into the notebook.  In order to do this, a closer look at the 1) City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/) and demographics.py call to Oxford API; and 2)scan-calculations.html file is necesessary.  Basically, where is the scan-calculations.html file population growth data coming from, and how can we get it into a csv file?\n",
    "pg = [\n",
    "    1969032 , 1984750, 2000614, 2016605, 2035590, 2070274, 2105593, 2141514,\n",
    "    2178094\t, 2215198, 2252984, 2291413, 2330547, 2370243, 2410667, 2449753, \n",
    "    2489472, 2529836, 2570854, 2612428, 2654378, 2696439\n",
    "]\n",
    "\n",
    "# create dataframe from pg list\n",
    "df = pd.DataFrame({\n",
    "    'yearName': years,\n",
    "    'population': pg\n",
    "})\n",
    "\n",
    "# calculate population growth rate as a percentage for each year and round it to 3 decimal places\n",
    "df['populationGrowthPercentage'] = df['population'].pct_change() * 100\n",
    "df['populationGrowthPercentage'] = df['populationGrowthPercentage'].round(3)\n",
    "\n",
    "# save to csv (no index)\n",
    "df.to_csv('data/processed/pg.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POPULATION DISTRIBUTION BY AGE & SEX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate population distribution data by age and sex for Tunis, Tunisia given scan-calculations.html file\n",
    "# Note: the intention is to write the scan-calculations population growth chart data to a csv file\n",
    "# and then read it into the notebook.  In order to do this, a closer look at the 1) City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/) and demographics.py call to Oxford/WorldPop API; and 2)scan-calculations.html file is necesessary.  Basically, where is the scan-calculations.html file population growth data coming from, and how can we get it into a csv file?\n",
    "pas = [\n",
    "    {\"ageBracket\": \"0-4\", \"sex\": \"female\", \"count\": 84255.76, \"percentage\": 0.037317174, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"0-4\", \"sex\": \"male\", \"count\": 90688.25, \"percentage\": 0.040166147, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"5-9\", \"sex\": \"female\", \"count\": 83410.27, \"percentage\": 0.036942703, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"5-9\", \"sex\": \"male\", \"count\": 90365.87, \"percentage\": 0.040023362, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"10-14\", \"sex\": \"female\", \"count\": 68791.52, \"percentage\": 0.030468006, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"10-14\", \"sex\": \"male\", \"count\": 72744.49, \"percentage\": 0.032218791, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"15-19\", \"sex\": \"female\", \"count\": 62009.60, \"percentage\": 0.027464272, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"15-19\", \"sex\": \"male\", \"count\": 65126.86, \"percentage\": 0.028844915, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"20-24\", \"sex\": \"female\", \"count\": 74367.26, \"percentage\": 0.032937522, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"20-24\", \"sex\": \"male\", \"count\": 75255.84, \"percentage\": 0.033331078, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"25-29\", \"sex\": \"female\", \"count\": 94742.76, \"percentage\": 0.041961902, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"25-29\", \"sex\": \"male\", \"count\": 90570.88, \"percentage\": 0.040114164, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"30-34\", \"sex\": \"female\", \"count\": 106160.84, \"percentage\": 0.047019010, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"30-34\", \"sex\": \"male\", \"count\": 103540.29, \"percentage\": 0.045858363, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"35-39\", \"sex\": \"female\", \"count\": 95786.56, \"percentage\": 0.042424208, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"35-39\", \"sex\": \"male\", \"count\": 94503.85, \"percentage\": 0.041856091, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"40-44\", \"sex\": \"female\", \"count\": 83400.61, \"percentage\": 0.036938427, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"40-44\", \"sex\": \"male\", \"count\": 84275.39, \"percentage\": 0.037325869, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"45-49\", \"sex\": \"female\", \"count\": 73773.45, \"percentage\": 0.032674520, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"45-49\", \"sex\": \"male\", \"count\": 71356.75, \"percentage\": 0.031604158, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"50-54\", \"sex\": \"female\", \"count\": 75568.57, \"percentage\": 0.033469589, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"50-54\", \"sex\": \"male\", \"count\": 75557.95, \"percentage\": 0.033464882, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"55-59\", \"sex\": \"female\", \"count\": 65577.59, \"percentage\": 0.029044548, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"55-59\", \"sex\": \"male\", \"count\": 68573.22, \"percentage\": 0.030371323, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"60-64\", \"sex\": \"female\", \"count\": 54934.92, \"percentage\": 0.024330870, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"60-64\", \"sex\": \"male\", \"count\": 58307.57, \"percentage\": 0.025824630, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"65-69\", \"sex\": \"female\", \"count\": 44470.28, \"percentage\": 0.019696046, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"65-69\", \"sex\": \"male\", \"count\": 42850.35, \"percentage\": 0.018978570, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"70-74\", \"sex\": \"female\", \"count\": 24648.85, \"percentage\": 0.010917065, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"70-74\", \"sex\": \"male\", \"count\": 22636.52, \"percentage\": 0.010025793, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"75-79\", \"sex\": \"female\", \"count\": 15277.18, \"percentage\": 0.006766316, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"75-79\", \"sex\": \"male\", \"count\": 13950.16, \"percentage\": 0.006178577, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"80+\", \"sex\": \"female\", \"count\": 16808.83, \"percentage\": 0.007444692, \"yearName\": \"2021\"},\n",
    "    {\"ageBracket\": \"80+\", \"sex\": \"male\", \"count\": 13538.88, \"percentage\": 0.005996419, \"yearName\": \"2021\"},\n",
    "]\n",
    "\n",
    "# convert pas list to dataframe, pas df\n",
    "pas_df = pd.DataFrame(pas)\n",
    "\n",
    "# create output CSV of pas_df for plotting\n",
    "pas_output_df = pd.DataFrame({\n",
    "    'ageBracket': pas_df['ageBracket'],\n",
    "    'sex': pas_df['sex'],\n",
    "    'count': pas_df['count'].round(2),  # round the count to 2 decimal places\n",
    "    'percentage': pas_df['percentage'] * 100,  # convert to percentage (multiply by 100)\n",
    "    'yearName': pas_df['yearName']\n",
    "})\n",
    "\n",
    "# sort by age bracket and sex to ensure proper ordering\n",
    "age_order = [\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-24\", \"25-29\", \"30-34\", \n",
    "             \"35-39\", \"40-44\", \"45-49\", \"50-54\", \"55-59\", \"60-64\", \n",
    "             \"65-69\", \"70-74\", \"75-79\", \"80+\"]\n",
    "\n",
    "pas_output_df['ageBracket'] = pd.Categorical(pas_output_df['ageBracket'], categories=age_order, ordered=True)\n",
    "pas_output_df = pas_output_df.sort_values(['ageBracket', 'sex'])\n",
    "\n",
    "# save pas_output_df for pas data to CSV\n",
    "pas_output_df.to_csv('data/processed/pas.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "  ageBracket     sex     count  percentage\n",
      "0        0-4  female  84255.76    3.731717\n",
      "1        0-4    male  90688.25    4.016615\n",
      "2        5-9  female  83410.27    3.694270\n",
      "3        5-9    male  90365.87    4.002336\n",
      "4      10-14  female  68791.52    3.046801\n",
      "5      10-14    male  72744.49    3.221879\n",
      "6      15-19  female  62009.60    2.746427\n",
      "7      15-19    male  65126.86    2.884491\n",
      "8      20-24  female  74367.26    3.293752\n",
      "9      20-24    male  75255.84    3.333108\n",
      "\n",
      "Total number of records: 34\n",
      "Age brackets: ['0-4', '5-9', '10-14', '15-19', '20-24', ..., '60-64', '65-69', '70-74', '75-79', '80+']\n",
      "Length: 17\n",
      "Categories (17, object): ['0-4' < '5-9' < '10-14' < '15-19' ... '65-69' < '70-74' < '75-79' < '80+']\n",
      "Sex categories: ['female' 'male']\n",
      "\n",
      "Total percentage: 100.00% (should be ~100%)\n"
     ]
    }
   ],
   "source": [
    "# pop_age_sex data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pop_age_sex_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pop_age_sex_output_df)}\")\n",
    "print(f\"Age brackets: {pop_age_sex_output_df['ageBracket'].unique()}\")\n",
    "print(f\"Sex categories: {pop_age_sex_output_df['sex'].unique()}\")\n",
    "\n",
    "# verify pop_age_sex data\n",
    "total_percentage = output_df['percentage'].sum()\n",
    "print(f\"\\nTotal percentage: {total_percentage:.2f}% (should be ~100%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 BUILT FORM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN EXTENT AND CHANGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate urban extent and change data for Tunis, Tunisia given \"tabular\" output from City Scan GCP process\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "uba = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"uba\": 166.08101814331798},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"uba\": 172.44786586480038},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"uba\": 185.11900630951914},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"uba\": 202.44611527369096},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"uba\": 209.3484337801595},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"uba\": 218.8655512133127},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"uba\": 226.97080233605266},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"uba\": 231.32775796388964},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"uba\": 235.31000915223282},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"uba\": 239.59690318203425},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"uba\": 244.28727695052265},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"uba\": 249.05396781687122},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"uba\": 253.29457114797057},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"uba\": 256.0263479213753},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"uba\": 258.9113844404829},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"uba\": 261.66818321318607},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"uba\": 264.4919158340125},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"uba\": 267.0854460612935},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"uba\": 270.3870988687197},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"uba\": 276.21722470525106},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"uba\": 281.41742170944474},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"uba\": 288.76825955333743},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"uba\": 294.66531923799204},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"uba\": 301.9654875333054},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"uba\": 310.2853023000293},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"uba\": 317.42908309972756},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"uba\": 322.2602056142696},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"uba\": 327.013134381004},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"uba\": 332.55550722560355},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"uba\": 337.01380195059915},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"uba\": 341.3507399789974}\n",
    "]\n",
    "\n",
    "# convert uba list to dataframe, uba_df\n",
    "uba_df = pd.DataFrame(uba)\n",
    "\n",
    "# create output CSV of df for plotting\n",
    "uba_output_df = pd.DataFrame({\n",
    "    'year': uba_df['year'],\n",
    "    'yearName': uba_df['yearName'],\n",
    "    'uba': uba_df['uba'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# calculate uba growth rate as a percentage for each year and round it to 3 decimal places\n",
    "uba_output_df['ubaGrowthPercentage'] = uba_output_df['uba'].pct_change() * 100\n",
    "uba_output_df['ubaGrowthPercentage'] = uba_output_df['ubaGrowthPercentage'].round(3)\n",
    "\n",
    "# save uba_output_df for uba data to CSV\n",
    "uba_output_df.to_csv('data/processed/uba.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName     uba\n",
      "0     1     1985  166.08\n",
      "1     2     1986  172.45\n",
      "2     3     1987  185.12\n",
      "3     4     1988  202.45\n",
      "4     5     1989  209.35\n",
      "5     6     1990  218.87\n",
      "6     7     1991  226.97\n",
      "7     8     1992  231.33\n",
      "8     9     1993  235.31\n",
      "9    10     1994  239.60\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "UBA values: [166.08 172.45 185.12 202.45 209.35 218.87 226.97 231.33 235.31 239.6\n",
      " 244.29 249.05 253.29 256.03 258.91 261.67 264.49 267.09 270.39 276.22\n",
      " 281.42 288.77 294.67 301.97 310.29 317.43 322.26 327.01 332.56 337.01\n",
      " 341.35]\n"
     ]
    }
   ],
   "source": [
    "# uba data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(uba_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(uba_output_df)}\")\n",
    "print(f\"Year names: {uba_output_df['yearName'].unique()}\")\n",
    "print(f\"UBA values: {uba_output_df['uba'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAND COVER (need alternative to donut chart - do tree map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Pixel Count'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# use the clean_land_cover_csv function from lc_cleanup.py to clean the tabular-output land cover csv file so that it can be plotted\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m clean_land_cover_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/raw/2025-02-tunisia-tunis_02-process-output_tabular_tunis_lc.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/processed/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/dev/wb/tunis-tunisia/src/lc_cleanup.py:31\u001b[0m, in \u001b[0;36mclean_land_cover_csv\u001b[0;34m(input_file, output_file)\u001b[0m\n\u001b[1;32m     28\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(input_file, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mland_cover_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_count\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# remove the apostrophes from \"pixel_count\" and convert to numeric\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_count\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# calculate \"total_pixels\" and \"percentage\"\u001b[39;00m\n\u001b[1;32m     34\u001b[0m total_pixels \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpixel_count\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    436\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'Pixel Count'"
     ]
    }
   ],
   "source": [
    "# use the clean_land_cover_csv function from lc_cleanup.py to clean the tabular-output land cover csv file so that it can be plotted\n",
    "clean_land_cover_csv('data/raw/2025-02-tunisia-tunis_02-process-output_tabular_tunis_lc.csv', 'data/processed/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# land cover data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## This needs to be automated given the tabular-output from the GCP - hard coded for now\n",
    "# (edit lc so that percentage is calculated from pixelCount and pixelTotal)\n",
    "lc = [\n",
    "      { \"lcType\": \"Built up\", \"pixelCount\": 3438092.2117647, \"pixelTotal\": 6068006.37255, \"percentage\": 56.66 },\n",
    "      { \"lcType\": \"Grassland\", \"pixelCount\": 1022591.69411765, \"pixelTotal\": 6068006.37255, \"percentage\": 16.85 },\n",
    "      { \"lcType\": \"Permanent water bodies\", \"pixelCount\": 563266.486274511, \"pixelTotal\": 6068006.37255, \"percentage\": 9.28},\n",
    "      { \"lcType\": \"Tree cover\", \"pixelCount\": 385035.090196078, \"pixelTotal\": 6068006.37255, \"percentage\": 6.345 },\n",
    "      { \"lcType\": \"Cropland\", \"pixelCount\": 346731.71372549, \"pixelTotal\": 6068006.37255, \"percentage\": 5.71},\n",
    "      { \"lcType\": \"Bare sparse vegetation\", \"pixelCount\": 168537.729411765, \"pixelTotal\": 6068006.37255, \"percentage\": 2.78},\n",
    "      { \"lcType\": \"Shrubland\", \"pixelCount\": 15153.5294117647, \"pixelTotal\": 6068006.37255, \"percentage\": 2.49},\n",
    "      { \"lcType\": \"Herbaceous wetland\", \"pixelCount\": 128597.917647059, \"pixelTotal\": 6068006.37255, \"percentage\": 2.12},\n",
    "      { \"lcType\": \"Snow and ice\", \"pixelCount\": 0, \"pixelTotal\": 6068006.37255, \"percentage\": 0},\n",
    "      { \"lcType\": \"Mangroves\", \"pixelCount\": 0, \"pixelTotal\": 6068006.37255, \"percentage\": 0},\n",
    "      { \"lcType\": \"Moss and lichens\", \"pixelCount\": 0, \"pixelTotal\": 6068006.37255, \"percentage\": 0},\n",
    "]\n",
    "\n",
    "# convert lc list to dataframe, lc_df\n",
    "lc_df = pd.DataFrame(lc)\n",
    "\n",
    "# create output CSV of lc_df for plotting\n",
    "lc_output_df = pd.DataFrame({\n",
    "    'lcType': lc_df['lcType'],\n",
    "    'pixelCount': lc_df['pixelCount'],\n",
    "    'pixelTotal': lc_df['pixelTotal'], \n",
    "    'percentage': lc_df['percentage']\n",
    "})\n",
    "\n",
    "# save lc_output_df for lc data to CSV\n",
    "lc_output_df.to_csv('data/processed/lc.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.5 POPULATION-URBAN GROWTH RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate population-urban grow for Tunis, Tunisia given pg.csv genergated via df and uba.csv generated via uba_output_df\n",
    "\n",
    "# read pg.csv and uba.csv\n",
    "pg_df = pd.read_csv('data/processed/pg.csv')\n",
    "uba_df = pd.read_csv('data/processed/uba.csv')\n",
    "\n",
    "# merge pg_df and uba_df on yearName\n",
    "merged_df = pd.merge(pg_df, uba_df, on='yearName', how='inner')\n",
    "\n",
    "# calculate population-urban growth ratio\n",
    "merged_df['populationUrbanGrowthRatio'] = merged_df['population'] / merged_df['uba']\n",
    "\n",
    "# save merged_df for population-urban growth ratio data to CSV\n",
    "merged_df.to_csv('data/processed/populationUrbanGrowthRatio.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 CLIMATE CONDITIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PHOTOVOLTAIC POWER POTENTIAL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate photovoltaic power potential data (i.e., seasonal availa bility of solar energy, plotting the \"max\" value ) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "pv = [\n",
    "      { \"month\": 1, \"monthName\": \"Jan\", \"max\": 3.31, \"min\": 3.04, \"mean\": 3.20},\n",
    "      { \"month\": 2, \"monthName\": \"Feb\", \"max\": 3.94, \"min\": 3.72, \"mean\": 3.84},\n",
    "      { \"month\": 3, \"monthName\": \"Mar\", \"max\": 4.53, \"min\": 4.32, \"mean\": 4.44},\n",
    "      { \"month\": 4, \"monthName\": \"Apr\", \"max\": 4.87, \"min\": 4.70, \"mean\": 4.79},\n",
    "      { \"month\": 5, \"monthName\": \"May\", \"max\": 5.17, \"min\": 4.99, \"mean\": 5.09},\n",
    "      { \"month\": 6, \"monthName\": \"Jun\", \"max\": 5.47, \"min\": 5.30, \"mean\": 5.39},\n",
    "      { \"month\": 7, \"monthName\": \"Jul\", \"max\": 5.68, \"min\": 5.52, \"mean\": 5.60},\n",
    "      { \"month\": 8, \"monthName\": \"Aug\", \"max\": 5.38, \"min\": 5.25, \"mean\": 5.31},\n",
    "      { \"month\": 9, \"monthName\": \"Sep\", \"max\": 4.59, \"min\": 4.40, \"mean\": 4.52},\n",
    "      { \"month\": 10, \"monthName\": \"Oct\", \"max\": 4.11, \"min\": 3.91, \"mean\": 4.03},\n",
    "      { \"month\": 11, \"monthName\": \"Nov\", \"max\": 3.44, \"min\": 3.13, \"mean\": 3.32},\n",
    "      { \"month\": 12, \"monthName\": \"Dec\", \"max\": 3.14, \"min\": 2.84, \"mean\": 3.03}\n",
    "]\n",
    "\n",
    "# convert pv list to dataframe, pv_df\n",
    "pv_df = pd.DataFrame(pv)\n",
    "\n",
    "# create output CSV of pv_df for plotting\n",
    "pv_output_df = pd.DataFrame({\n",
    "    'month': pv_df['month'],\n",
    "    'monthName': pv_df['monthName'],\n",
    "    'maxPv': pv_df['max'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save pv_output_df for pv data to CSV\n",
    "pv_output_df.to_csv('data/processed/pv.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   month monthName  maxPv\n",
      "0      1       Jan   3.31\n",
      "1      2       Feb   3.94\n",
      "2      3       Mar   4.53\n",
      "3      4       Apr   4.87\n",
      "4      5       May   5.17\n",
      "5      6       Jun   5.47\n",
      "6      7       Jul   5.68\n",
      "7      8       Aug   5.38\n",
      "8      9       Sep   4.59\n",
      "9     10       Oct   4.11\n",
      "\n",
      "Total number of records: 12\n",
      "Month names: ['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec']\n",
      "PV values: [3.31 3.94 4.53 4.87 5.17 5.47 5.68 5.38 4.59 4.11 3.44 3.14]\n"
     ]
    }
   ],
   "source": [
    "# pv data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pv_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pv_output_df)}\")\n",
    "print(f\"Month names: {pv_output_df['monthName'].unique()}\")\n",
    "print(f\"PV values: {pv_output_df['maxPv'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 RISK IDENTIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO RIVER FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to river flooding data (i.e., built-up area exposed to fluvial flooding) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "fu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"fu\": 3.351537941381818},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"fu\": 3.4746915665244567},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"fu\": 3.6828798375989176},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"fu\": 3.9775688691902324},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"fu\": 4.116849754768217},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"fu\": 4.237071150740793},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"fu\": 4.441594135352676},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"fu\": 4.598468395951038},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"fu\": 4.801525265977889},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"fu\": 5.022908568317633},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"fu\": 5.185647287256121},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"fu\": 5.427556193786304},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"fu\": 5.631346121105671},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"fu\": 5.777957579608812},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"fu\": 6.023531772601575},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"fu\": 6.172342402982264},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"fu\": 6.3563397834037065},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"fu\": 6.53667187736257},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"fu\": 6.648829643117474},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"fu\": 6.747059320314579},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"fu\": 6.824763393321244},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"fu\": 6.928857528858474},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"fu\": 7.034417778980736},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"fu\": 7.114321023864949},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"fu\": 7.191292039579098},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"fu\": 7.28658948760614},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"fu\": 7.3327720970346295},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"fu\": 7.450061263837143},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"fu\": 7.5050405607758215},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"fu\": 7.6149991546531774},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"fu\": 7.672177623469403},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert fu list to dataframe, fu_df\n",
    "fu_df = pd.DataFrame(fu)\n",
    "\n",
    "# create output CSV of fu_df for plotting\n",
    "fu_output_df = pd.DataFrame({\n",
    "    'year': fu_df['year'],\n",
    "    'yearName': fu_df['yearName'],\n",
    "    'fu': fu_df['fu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save fu_output_df for fu data to CSV\n",
    "fu_output_df.to_csv('data/processed/fu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName    fu\n",
      "0     1     1985  3.35\n",
      "1     2     1986  3.47\n",
      "2     3     1987  3.68\n",
      "3     4     1988  3.98\n",
      "4     5     1989  4.12\n",
      "5     6     1990  4.24\n",
      "6     7     1991  4.44\n",
      "7     8     1992  4.60\n",
      "8     9     1993  4.80\n",
      "9    10     1994  5.02\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "fu values: [3.35 3.47 3.68 3.98 4.12 4.24 4.44 4.6  4.8  5.02 5.19 5.43 5.63 5.78\n",
      " 6.02 6.17 6.36 6.54 6.65 6.75 6.82 6.93 7.03 7.11 7.19 7.29 7.33 7.45\n",
      " 7.51 7.61 7.67]\n"
     ]
    }
   ],
   "source": [
    "# fu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(fu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(fu_output_df)}\")\n",
    "print(f\"Year names: {fu_output_df['yearName'].unique()}\")\n",
    "print(f\"fu values: {fu_output_df['fu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO RAINWATER FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to rainwater flooding data (i.e., built-up area exposed to pluvial flooding) for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "pu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"pu\": 29.78265168032819},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"pu\": 31.410038869713063},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"pu\": 33.22875401244453},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"pu\": 34.975629540509466},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"pu\": 36.07668159386806},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"pu\": 37.00913046994804},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"pu\": 38.23993366408192},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"pu\": 39.27867584757668},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"pu\": 40.277099879983076},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"pu\": 41.435330402157895},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"pu\": 42.235095908292536},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"pu\": 43.18880344585547},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"pu\": 44.074336655214445},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"pu\": 44.960602921865934},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"pu\": 45.93630217820434},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"pu\": 46.66862641342754},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"pu\": 47.94121387323481},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"pu\": 49.155156749640824},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"pu\": 50.08247422467319},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"pu\": 50.62566967842733},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"pu\": 51.11975029358292},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"pu\": 51.73405230471108},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"pu\": 52.47737239932201},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"pu\": 53.22948918144312},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"pu\": 53.95374978644864},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"pu\": 54.567318740284286},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"pu\": 54.98369528243321},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"pu\": 55.5386196528676},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"pu\": 56.0422300128259},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"pu\": 56.627209732253434},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"pu\": 56.92336487842978},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert pu list to dataframe, pu_df\n",
    "pu_df = pd.DataFrame(pu)\n",
    "\n",
    "# create output CSV of pu_df for plotting\n",
    "pu_output_df = pd.DataFrame({\n",
    "    'year': pu_df['year'],\n",
    "    'yearName': pu_df['yearName'],\n",
    "    'pu': pu_df['pu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save pu_output_df for pu data to CSV\n",
    "pu_output_df.to_csv('data/processed/pu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName     pu\n",
      "0     1     1985  29.78\n",
      "1     2     1986  31.41\n",
      "2     3     1987  33.23\n",
      "3     4     1988  34.98\n",
      "4     5     1989  36.08\n",
      "5     6     1990  37.01\n",
      "6     7     1991  38.24\n",
      "7     8     1992  39.28\n",
      "8     9     1993  40.28\n",
      "9    10     1994  41.44\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "pu values: [29.78 31.41 33.23 34.98 36.08 37.01 38.24 39.28 40.28 41.44 42.24 43.19\n",
      " 44.07 44.96 45.94 46.67 47.94 49.16 50.08 50.63 51.12 51.73 52.48 53.23\n",
      " 53.95 54.57 54.98 55.54 56.04 56.63 56.92]\n"
     ]
    }
   ],
   "source": [
    "# pu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(pu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(pu_output_df)}\")\n",
    "print(f\"Year names: {pu_output_df['yearName'].unique()}\")\n",
    "print(f\"pu values: {pu_output_df['pu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO COASTAL FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to coastal flooding data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "cu = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"cu\": 2.2739437213837266},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"cu\": 2.5451749196145386},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"cu\": 2.833266435573212},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"cu\": 2.955687003423335},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"cu\": 3.063446425423144},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"cu\": 3.1396843838447777},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"cu\": 3.2349818318718198},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"cu\": 3.317084248633579},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"cu\": 3.3815932903749615},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"cu\": 3.4636957071367207},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"cu\": 3.53040392075565},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"cu\": 3.600777420837158},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"cu\": 3.6652864625785404},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"cu\": 3.7437235928777213},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"cu\": 3.811164863789166},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"cu\": 3.8639449888502972},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"cu\": 3.942382119149478},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"cu\": 4.03254816612891},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"cu\": 4.176960452754504},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"cu\": 4.2385372653258235},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"cu\": 4.319906624795067},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"cu\": 4.385881781121481},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"cu\": 4.469450312468272},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"cu\": 4.6079981407537405},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"cu\": 4.754609599256882},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"cu\": 4.844042588943799},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"cu\": 4.96499704220889},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"cu\": 5.050764745433228},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"cu\": 5.168053912235742},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"cu\": 5.225232381051967},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"cu\": 5.311733141568821},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert cu list to dataframe, cu_df\n",
    "cu_df = pd.DataFrame(cu)\n",
    "\n",
    "# create output CSV of cu_df for plotting\n",
    "cu_output_df = pd.DataFrame({\n",
    "    'year': cu_df['year'],\n",
    "    'yearName': cu_df['yearName'],\n",
    "    'cu': cu_df['cu'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save cu_output_df for cu data to CSV\n",
    "cu_output_df.to_csv('data/processed/cu.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName    cu\n",
      "0     1     1985  2.27\n",
      "1     2     1986  2.55\n",
      "2     3     1987  2.83\n",
      "3     4     1988  2.96\n",
      "4     5     1989  3.06\n",
      "5     6     1990  3.14\n",
      "6     7     1991  3.23\n",
      "7     8     1992  3.32\n",
      "8     9     1993  3.38\n",
      "9    10     1994  3.46\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "cu values: [2.27 2.55 2.83 2.96 3.06 3.14 3.23 3.32 3.38 3.46 3.53 3.6  3.67 3.74\n",
      " 3.81 3.86 3.94 4.03 4.18 4.24 4.32 4.39 4.47 4.61 4.75 4.84 4.96 5.05\n",
      " 5.17 5.23 5.31]\n"
     ]
    }
   ],
   "source": [
    "# cu data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(cu_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(cu_output_df)}\")\n",
    "print(f\"Year names: {cu_output_df['yearName'].unique()}\")\n",
    "print(f\"cu values: {cu_output_df['cu'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URBAN BUILT-UP AREA EXPOSED TO COMBINED RIVER, RAINWATER, AND COASTAL FLOODING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate built-up area exposed to combined flooding data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "comb = [\n",
    "      { \"year\": 1, \"yearName\": \"1985\", \"comb\": 32.76106345981951},\n",
    "      { \"year\": 2, \"yearName\": \"1986\", \"comb\": 34.641355415122305},\n",
    "      { \"year\": 3, \"yearName\": \"1987\", \"comb\": 36.74669595922742},\n",
    "      { \"year\": 4, \"yearName\": \"1988\", \"comb\": 38.72814982089738},\n",
    "      { \"year\": 5, \"yearName\": \"1989\", \"comb\": 39.97801250463666},\n",
    "      { \"year\": 6, \"yearName\": \"1990\", \"comb\": 41.01895386000896},\n",
    "      { \"year\": 7, \"yearName\": \"1991\", \"comb\": 42.41176271578881},\n",
    "      { \"year\": 8, \"yearName\": \"1992\", \"comb\": 43.57512463901124},\n",
    "      { \"year\": 9, \"yearName\": \"1993\", \"comb\": 44.71063038511807},\n",
    "      { \"year\": 10, \"yearName\": \"1994\", \"comb\": 46.004476506408295},\n",
    "      { \"year\": 11, \"yearName\": \"1995\", \"comb\": 46.92373035122299},\n",
    "      { \"year\": 12, \"yearName\": \"1996\", \"comb\": 48.01525265977888},\n",
    "      { \"year\": 13, \"yearName\": \"1997\", \"comb\": 49.01514280677031},\n",
    "      { \"year\": 14, \"yearName\": \"1998\", \"comb\": 50.03116021419708},\n",
    "      { \"year\": 15, \"yearName\": \"1999\", \"comb\": 51.17326347593655},\n",
    "      { \"year\": 16, \"yearName\": \"2000\", \"comb\": 52.02727522171735},\n",
    "      { \"year\": 17, \"yearName\": \"2001\", \"comb\": 53.43621133793255},\n",
    "      { \"year\": 18, \"yearName\": \"2002\", \"comb\": 54.78357064157642},\n",
    "      { \"year\": 19, \"yearName\": \"2003\", \"comb\": 55.887554924105075},\n",
    "      { \"year\": 20, \"yearName\": \"2004\", \"comb\": 56.53850979985902},\n",
    "      { \"year\": 21, \"yearName\": \"2005\", \"comb\": 57.14034983701442},\n",
    "      { \"year\": 22, \"yearName\": \"2006\", \"comb\": 57.87780547328522},\n",
    "      { \"year\": 23, \"yearName\": \"2007\", \"comb\": 58.721554416970804},\n",
    "      { \"year\": 24, \"yearName\": \"2008\", \"comb\": 59.591693423186946},\n",
    "      { \"year\": 25, \"yearName\": \"2009\", \"comb\": 60.43690848145756},\n",
    "      { \"year\": 26, \"yearName\": \"2010\", \"comb\": 61.1435757114427},\n",
    "      { \"year\": 27, \"yearName\": \"2011\", \"comb\": 61.66038110266628},\n",
    "      { \"year\": 28, \"yearName\": \"2012\", \"comb\": 62.301073176325005},\n",
    "      { \"year\": 29, \"yearName\": \"2013\", \"comb\": 62.89631569784776},\n",
    "      { \"year\": 30, \"yearName\": \"2014\", \"comb\": 63.53700777150649},\n",
    "      { \"year\": 31, \"yearName\": \"2015\", \"comb\": 63.918197563614655},  \n",
    "\n",
    "]\n",
    "\n",
    "# convert comb list to dataframe, comb_df\n",
    "comb_df = pd.DataFrame(comb)\n",
    "\n",
    "# create output CSV of comb_df for plotting\n",
    "comb_output_df = pd.DataFrame({\n",
    "    'year': comb_df['year'],\n",
    "    'yearName': comb_df['yearName'],\n",
    "    'comb': comb_df['comb'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save comb_output_df for comb data to CSV\n",
    "comb_output_df.to_csv('data/processed/comb.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   year yearName   comb\n",
      "0     1     1985  32.76\n",
      "1     2     1986  34.64\n",
      "2     3     1987  36.75\n",
      "3     4     1988  38.73\n",
      "4     5     1989  39.98\n",
      "5     6     1990  41.02\n",
      "6     7     1991  42.41\n",
      "7     8     1992  43.58\n",
      "8     9     1993  44.71\n",
      "9    10     1994  46.00\n",
      "\n",
      "Total number of records: 31\n",
      "Year names: ['1985' '1986' '1987' '1988' '1989' '1990' '1991' '1992' '1993' '1994'\n",
      " '1995' '1996' '1997' '1998' '1999' '2000' '2001' '2002' '2003' '2004'\n",
      " '2005' '2006' '2007' '2008' '2009' '2010' '2011' '2012' '2013' '2014'\n",
      " '2015']\n",
      "comb values: [32.76 34.64 36.75 38.73 39.98 41.02 42.41 43.58 44.71 46.   46.92 48.02\n",
      " 49.02 50.03 51.17 52.03 53.44 54.78 55.89 56.54 57.14 57.88 58.72 59.59\n",
      " 60.44 61.14 61.66 62.3  62.9  63.54 63.92]\n"
     ]
    }
   ],
   "source": [
    "# comb data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(comb_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(comb_output_df)}\")\n",
    "print(f\"Year names: {comb_output_df['yearName'].unique()}\")\n",
    "print(f\"comb values: {comb_output_df['comb'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELEVATION (need alternative to donut chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# elevation data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## This needs to be automated given the tabular-output from the GCP - hard coded for now\n",
    "\n",
    "elevation = [\n",
    "      { \"bin\": \"-5-40m\", \"count\": 413599, \"total\": 549697, \"percentage\": 75.24},\n",
    "      { \"bin\": \"40-90m\", \"count\": 94379, \"total\": 549697, \"percentage\": 17.17 },\n",
    "      { \"bin\": \"90-135m\", \"count\": 32786 , \"total\": 549697, \"percentage\": 5.96 },\n",
    "      { \"bin\": \"135-185m\", \"count\": 8043, \"total\": 549697, \"percentage\": 1.46 },\n",
    "      { \"bin\": \"135-235\", \"count\": 890, \"total\": 549697, \"percentage\": 0.16 },\n",
    "]\n",
    "\n",
    "# convert elevation list to dataframe, elevation_df\n",
    "elevation_df = pd.DataFrame(elevation)\n",
    "\n",
    "# create output CSV of elevation_df for plotting\n",
    "elevation_output_df = pd.DataFrame({\n",
    "    'bin': elevation_df['bin'],\n",
    "    'count': elevation_df['count'],\n",
    "    'total': elevation_df['total'], \n",
    "    'percentage': elevation_df['percentage']\n",
    "})\n",
    "\n",
    "# save elevation_output_df for elevation data to CSV\n",
    "elevation_output_df.to_csv('data/processed/elevation.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SLOPE (need alternative to donut chart)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# slope data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "## This needs to be automated given the tabular-output from the GCP - hard coded for now\n",
    "\n",
    "slope = [\n",
    "      { \"bin\": \"0-2\", \"count\": 428343, \"total\": 549702, \"percentage\": 77.92 },\n",
    "      { \"bin\": \"2-5\", \"count\": 79034, \"total\": 549702, \"percentage\": 14.38 },\n",
    "      { \"bin\": \"5-10\", \"count\": 31121, \"total\": 549702, \"percentage\": 5.66 },\n",
    "      { \"bin\": \"10-20\", \"count\": 10147, \"total\": 549702, \"percentage\": 1.85 },\n",
    "      { \"bin\": \"20+\", \"count\": 1057, \"total\": 549702, \"percentage\": 0.19 },\n",
    "]\n",
    "\n",
    "# convert slope list to dataframe, slope_df\n",
    "slope_df = pd.DataFrame(slope)\n",
    "\n",
    "# create output CSV of slope_df for plotting\n",
    "slope_output_df = pd.DataFrame({\n",
    "    'bin': slope_df['bin'],\n",
    "    'count': slope_df['count'],\n",
    "    'total': slope_df['total'], \n",
    "    'percentage': slope_df['percentage']\n",
    "})\n",
    "\n",
    "# save slope_output_df for slope data to CSV\n",
    "slope_output_df.to_csv('data/processed/slope.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EARTHQUAKE EVENTS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate earthquake event data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "# manually added earthquake event data for Tunis, Tunisia\n",
    "ee = [\n",
    "    {\"begin_year\": 1903, \"distance\": 316, \"eqMagnitude\": 5.3, \"severity\": \"Moderate\", \"text\": \"MAY 1903; MNA; 316 km away; NA damage\", \"line1\": \"MAY 1903\", \"line2\": \"M5.3, 316 km away\", \"line3\": \"Palermo\"},\n",
    "    {\"begin_year\": 1906, \"distance\": 335, \"eqMagnitude\": 5.6, \"severity\": \"Large\", \"text\": \"SEPTEMBER 1906; MNA; 336 km away; NA damage\", \"line1\": \"SEPTEMBER 1906\", \"line2\": \"M5.6, 335 km away\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1907, \"distance\": 335, \"eqMagnitude\": 5.1, \"severity\": \"Moderate\", \"text\": \"FEBRUARY 1907; MNA; 336 km away; NA damage\", \"line1\": \"FEBRUARY 1907\", \"line2\": \"M5.1, 335 km away\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1908, \"distance\": 497, \"eqMagnitude\": 7.0, \"severity\": \"Very Large\", \"text\": \"DECEMBER 1908; M7; 498 km away; Extreme damage; 78,000 fatalities\", \"line1\": \"DECEMBER 1908\", \"line2\": \"M7.0, 498 km away, 78,000 fatalities\", \"line3\": \"Messina, Sicily, Calabria\"},\n",
    "    {\"begin_year\": 1909, \"distance\": 452, \"eqMagnitude\": 5.3, \"severity\": \"Moderate\", \"text\": \"OCTOBER 1909; MNA; 453 km away; NA damage\", \"line1\": \"OCTOBER 1909\", \"line2\": \"M5.3, 453 km away\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1911, \"distance\": 652, \"eqMagnitude\": 4.3, \"severity\": \"Small\", \"text\": \"OCTOBER 1911; M4.3; 453 km away; NA damage\", \"line1\": \"OCTOBER 1911\", \"line2\": \"M4.3, 453 km away\", \"line3\": \"Etna\"},\n",
    "    {\"begin_year\": 1914, \"distance\": 452, \"eqMagnitude\": 4.9, \"severity\": \"Small\", \"text\": \"MAY 1914; M4.9; 453 km away; Severe damage; 120 fatalities\", \"line1\": \"MAY 1914\", \"line2\": \"M4.9, 453 km away, 120 fatalities\", \"line3\": \"Catania, Etna\"},\n",
    "    {\"begin_year\": 1916, \"distance\": 494, \"eqMagnitude\": 5.1, \"severity\": \"Moderate\", \"text\": \"JULY 1916; M5.1; 494 km away; Limited damage\", \"line1\": \"JULY 1916\", \"line2\": \"M5.1, 494 km away\", \"line3\": \"Stromboli Island\"},\n",
    "    {\"begin_year\": 1924, \"distance\": 489, \"eqMagnitude\": 5.6, \"severity\": \"Large\", \"text\": \"MARCH 1924; M5.6; 489 km away; NA damage\", \"line1\": \"MARCH 1924\", \"line2\": \"M5.6, 489 km away\", \"line3\": \"Batna\"},\n",
    "    {\"begin_year\": 1926, \"distance\": 451, \"eqMagnitude\": 5.3, \"severity\": \"Moderate\", \"text\": \"AUGUST 1926; M5.3; 451 km away; Severe damage\", \"line1\": \"AUGUST 1926\", \"line2\": \"M5.3, 451 km away\", \"line3\": \"Salina Island\"},\n",
    "    {\"begin_year\": 1930, \"distance\": 434, \"eqMagnitude\": 5.0, \"severity\": \"Moderate\", \"text\": \"MARCH 1930; MNA; 434 km away; Moderate damage\", \"line1\": \"MARCH 1930\", \"line2\": \"M5.0, 434 km away\", \"line3\": \"Filicudi Island\"},\n",
    "    {\"begin_year\": 1931, \"distance\": 444, \"eqMagnitude\": 5.0, \"severity\": \"Moderate\", \"text\": \"JULY 1931; MNA; 444 km away; NA damage\", \"line1\": \"JULY 1931\", \"line2\": \"M5.0, 444 km away\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1933, \"distance\": 256, \"eqMagnitude\": 5.0, \"severity\": \"Moderate\", \"text\": \"FEBRUARY 1933; MNA; 256 km away; NA damage\", \"line1\": \"FEBRUARY 1933\", \"line2\": \"M5.0, 256 km away\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1939, \"distance\": 437, \"eqMagnitude\": 5.0, \"severity\": \"Moderate\", \"text\": \"JANUARY 1939; MNA; 438 km away; NA damage\", \"line1\": \"JANUARY 1939\", \"line2\": \"M5.0, 438 km away\", \"line3\": \"Calabria\"},\n",
    "    {\"begin_year\": 1940, \"distance\": 323, \"eqMagnitude\": 4.8, \"severity\": \"Small\", \"text\": \"JANUARY 1940; M4.8; 324 km away; NA damage\", \"line1\": \"JANUARY 1940\", \"line2\": \"M4.8, 324 km away\", \"line3\": \"NA\"},\n",
    "    {\"begin_year\": 1941, \"distance\": 240, \"eqMagnitude\": 5.0, \"severity\": \"Moderate\", \"text\": \"MARCH 1941; MNA; 241 km away; NA damage\", \"line1\": \"MARCH 1941\", \"line2\": \"M5.0, 241 km away\", \"line3\": \"Calabria\"},\n",
    "    {\"begin_year\": 1946, \"distance\": 481, \"eqMagnitude\": 5.6, \"severity\": \"Large\", \"text\": \"FEBRUARY 1946; M5.6; 481 km away; Severe damage; 264 fatalities\", \"line1\": \"FEBRUARY 1946\", \"line2\": \"M5.6, 481 km away, 264 fatalities\", \"line3\": \"Hodna Mountains\"},\n",
    "    {\"begin_year\": 1947, \"distance\": 196, \"eqMagnitude\": 5.3, \"severity\": \"Moderate\", \"text\": \"AUGUST 1947; M5.3; 197 km away; Moderate damage; 3 fatalities\", \"line1\": \"AUGUST 1947\", \"line2\": \"M5.3, 197 km away, 3 fatalities\", \"line3\": \"NA\"},\n",
    "    {\"begin_year\": 1957, \"distance\": 135, \"eqMagnitude\": 5.6, \"severity\": \"Large\", \"text\": \"FEBRUARY 1957; M5.6; 135 km away; Moderate damage; 13 fatalities\", \"line1\": \"FEBRUARY 1957\", \"line2\": \"M5.6, 135 km away, 13 fatalities\", \"line3\": \"Sidi Abd,Sidi Toul\"},\n",
    "    {\"begin_year\": 1961, \"distance\": 468, \"eqMagnitude\": 5.0, \"severity\": \"Moderate\", \"text\": \"MARCH 1961; MNA; 469 km away; Moderate damage; 15 fatalities\", \"line1\": \"MARCH 1961\", \"line2\": \"M5.0, 469 km away, 15 fatalities\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1962, \"distance\": 141, \"eqMagnitude\": 5.3, \"severity\": \"Moderate\", \"text\": \"FEBRUARY 1962; M5.3; 141 km away; Moderate damage\", \"line1\": \"FEBRUARY 1962\", \"line2\": \"M5.3, 141 km away\", \"line3\": \"Gafour,OUM-Zid,EL Akhouат\"},\n",
    "    {\"begin_year\": 1968, \"distance\": 282, \"eqMagnitude\": 6.0, \"severity\": \"Very Large\", \"text\": \"JANUARY 1968; M6; 283 km away; Extreme damage; 216 fatalities\", \"line1\": \"JANUARY 1968\", \"line2\": \"M6.0, 283 km away, 216 fatalities\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1968, \"distance\": 466, \"eqMagnitude\": 4.9, \"severity\": \"Small\", \"text\": \"FEBRUARY 1968; M4.9; 466 km away; Moderate damage; 1 fatality\", \"line1\": \"FEBRUARY 1968\", \"line2\": \"M4.9, 466 km away, 1 fatality\", \"line3\": \"El Asn (BABORD)\"},\n",
    "    {\"begin_year\": 1975, \"distance\": 446, \"eqMagnitude\": 4.3, \"severity\": \"Small\", \"text\": \"JULY 1975; M4.3; 446 km away; Moderate damage; 1 fatality\", \"line1\": \"JULY 1975\", \"line2\": \"M4.3, 446 km away, 1 fatality\", \"line3\": \"Djebel Babor\"},\n",
    "    {\"begin_year\": 1978, \"distance\": 462, \"eqMagnitude\": 5.7, \"severity\": \"Large\", \"text\": \"APRIL 1978; M5.7; 463 km away; Moderate damage; 5 fatalities\", \"line1\": \"APRIL 1978\", \"line2\": \"M5.7, 463 km away, 5 fatalities\", \"line3\": \"Sicily\"},\n",
    "    {\"begin_year\": 1990, \"distance\": 467, \"eqMagnitude\": 5.3, \"severity\": \"Moderate\", \"text\": \"DECEMBER 1990; M5.3; 468 km away; Extreme damage; 19 fatalities\", \"line1\": \"DECEMBER 1990\", \"line2\": \"M5.3, 468 km away, 19 fatalities\", \"line3\": \"Sicily: Carlentini\"},\n",
    "    {\"begin_year\": 2002, \"distance\": 553, \"eqMagnitude\": 6.0, \"severity\": \"Very Large\", \"text\": \"SEPTEMBER 2002; M6; 354 km away; Extreme damage; 2 fatalities\", \"line1\": \"SEPTEMBER 2002\", \"line2\": \"M6.0, 354 km away, 2 fatalities\", \"line3\": \"Sicily: Palermo\"},\n",
    "    {\"begin_year\": 2018, \"distance\": 442, \"eqMagnitude\": 5.0, \"severity\": \"Moderate\", \"text\": \"DECEMBER 2018; M5; 443 km away; Extreme damage\", \"line1\": \"DECEMBER 2018\", \"line2\": \"M5.0, 443 km away\", \"line3\": \"Sicily: Catpana\"},\n",
    "    {\"begin_year\": 2021, \"distance\": 444, \"eqMagnitude\": 6.0, \"severity\": \"Very Large\", \"text\": \"MARCH 2021; M6; 445 km away; Limited damage\", \"line1\": \"MARCH 2021\", \"line2\": \"M6.0, 445 km away\", \"line3\": \"NA\"}\n",
    "]\n",
    "\n",
    "# convert ee list to dataframe, ee_df\n",
    "ee_df = pd.DataFrame(ee)\n",
    "\n",
    "\n",
    "# save ee_output_df for ee data to CSV\n",
    "ee_df.to_csv('data/processed/ee.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   begin_year  distance  eqMagnitude    severity           line1  \\\n",
      "0        1903       316          5.3    Moderate        MAY 1903   \n",
      "1        1906       335          5.6       Large  SEPTEMBER 1906   \n",
      "2        1907       335          5.1    Moderate   FEBRUARY 1907   \n",
      "3        1908       497          7.0  Very Large   DECEMBER 1908   \n",
      "4        1909       452          5.3    Moderate    OCTOBER 1909   \n",
      "5        1911       652          4.3       Small    OCTOBER 1911   \n",
      "6        1914       452          4.9       Small        MAY 1914   \n",
      "7        1916       494          5.1    Moderate       JULY 1916   \n",
      "8        1924       489          5.6       Large      MARCH 1924   \n",
      "9        1926       451          5.3    Moderate     AUGUST 1926   \n",
      "\n",
      "                                  line2                      line3  \n",
      "0                     M5.3, 316 km away                    Palermo  \n",
      "1                     M5.6, 335 km away                     Sicily  \n",
      "2                     M5.1, 335 km away                     Sicily  \n",
      "3  M7.0, 498 km away, 78,000 fatalities  Messina, Sicily, Calabria  \n",
      "4                     M5.3, 453 km away                     Sicily  \n",
      "5                     M4.3, 453 km away                       Etna  \n",
      "6     M4.9, 453 km away, 120 fatalities              Catania, Etna  \n",
      "7                     M5.1, 494 km away           Stromboli Island  \n",
      "8                     M5.6, 489 km away                      Batna  \n",
      "9                     M5.3, 451 km away              Salina Island  \n"
     ]
    }
   ],
   "source": [
    "# ee data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(ee_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HISTORICAL BURNT AREA & FIRE WEATHER INDEX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file created successfully.\n"
     ]
    }
   ],
   "source": [
    "# generate historical burnt area & fire weather index data for Tunis, Tunisia\n",
    "# Note: City Scan GitHub (https://github.com/rosemaryturtle/city-scan-automation/)\n",
    "\n",
    "fwi = [\n",
    "      { \"week\": 1, \"monthName\": \"Jan\", \"fwi\": 36.03855628967285},\n",
    "      { \"week\": 2, \"monthName\": \"Jan\", \"fwi\": 28.35186767578125},\n",
    "      { \"week\": 3, \"monthName\": \"Jan\", \"fwi\": 34.48613758087156},\n",
    "      { \"week\": 4, \"monthName\": \"Jan\", \"fwi\": 35.160119628906244},\n",
    "      { \"week\": 5, \"monthName\": \"Feb\", \"fwi\": 41.2155460357666},\n",
    "      { \"week\": 6, \"monthName\": \"Feb\", \"fwi\": 42.91906299591064},\n",
    "      { \"week\": 7, \"monthName\": \"Feb\", \"fwi\": 40.35708732604981},\n",
    "      { \"week\": 8, \"monthName\": \"Feb\", \"fwi\": 35.13482322692871},\n",
    "      { \"week\": 9, \"monthName\": \"Feb\", \"fwi\": 43.7328405380249},\n",
    "      { \"week\": 10, \"monthName\": \"Mar\", \"fwi\": 55.629536437988264},\n",
    "      { \"week\": 11, \"monthName\": \"Mar\", \"fwi\": 51.963145637512206},\n",
    "      { \"week\": 12, \"monthName\": \"Mar\", \"fwi\": 48.64410858154295},\n",
    "      { \"week\": 13, \"monthName\": \"Mar\", \"fwi\": 48.45940856933592},\n",
    "      { \"week\": 14, \"monthName\": \"Apr\", \"fwi\": 42.525428390502924},\n",
    "      { \"week\": 15, \"monthName\": \"Apr\", \"fwi\": 48.989934921264634},\n",
    "      { \"week\": 16, \"monthName\": \"Apr\", \"fwi\": 47.94815864562989},\n",
    "      { \"week\": 17, \"monthName\": \"Apr\", \"fwi\": 59.693392562866215},\n",
    "      { \"week\": 18, \"monthName\": \"May\", \"fwi\": 53.26485347747803},\n",
    "      { \"week\": 19, \"monthName\": \"May\", \"fwi\": 67.04015121459962},\n",
    "      { \"week\": 20, \"monthName\": \"May\", \"fwi\": 66.2925880432129},\n",
    "      { \"week\": 21, \"monthName\": \"May\", \"fwi\": 63.51103172302246},\n",
    "      { \"week\": 22, \"monthName\": \"May\", \"fwi\": 57.59551124572754},\n",
    "      { \"week\": 23, \"monthName\": \"Jun\", \"fwi\": 66.97727813720704},\n",
    "      { \"week\": 24, \"monthName\": \"Jun\", \"fwi\": 75.7531303405762},\n",
    "      { \"week\": 25, \"monthName\": \"Jun\", \"fwi\": 80.30134506225586},\n",
    "      { \"week\": 26, \"monthName\": \"Jun\", \"fwi\": 90.69736862182619},\n",
    "      { \"week\": 27, \"monthName\": \"Jul\", \"fwi\": 75.26012268066407},\n",
    "      { \"week\": 28, \"monthName\": \"Jul\", \"fwi\": 95.59054870605469},\n",
    "      { \"week\": 29, \"monthName\": \"Jul\", \"fwi\": 82.06852722167967},\n",
    "      { \"week\": 30, \"monthName\": \"Jul\", \"fwi\": 81.8968620300293},\n",
    "      { \"week\": 31, \"monthName\": \"Aug\", \"fwi\": 81.7047821044922},\n",
    "      { \"week\": 32, \"monthName\": \"Aug\", \"fwi\": 81.58447265625001}, \n",
    "      { \"week\": 33, \"monthName\": \"Aug\", \"fwi\": 65.29224243164063},  \n",
    "      { \"week\": 34, \"monthName\": \"Aug\", \"fwi\": 67.29769515991212},  \n",
    "      { \"week\": 35, \"monthName\": \"Aug\", \"fwi\": 64.21281738281252},  \n",
    "      { \"week\": 36, \"monthName\": \"Sep\", \"fwi\": 69.20558013916019},  \n",
    "      { \"week\": 37, \"monthName\": \"Sep\", \"fwi\": 59.376176834106474},  \n",
    "      { \"week\": 38, \"monthName\": \"Sep\", \"fwi\": 50.01441955566406},  \n",
    "      { \"week\": 39, \"monthName\": \"Sep\", \"fwi\": 40.38814010620118 },  \n",
    "      { \"week\": 40, \"monthName\": \"Oct\", \"fwi\": 48.369334793090815},  \n",
    "      { \"week\": 41, \"monthName\": \"Oct\", \"fwi\": 43.82190437316895},  \n",
    "      { \"week\": 42, \"monthName\": \"Oct\", \"fwi\": 37.03949813842773},  \n",
    "      { \"week\": 43, \"monthName\": \"Oct\", \"fwi\": 50.04811096191406},  \n",
    "      { \"week\": 44, \"monthName\": \"Nov\", \"fwi\": 47.38101158142093},  \n",
    "      { \"week\": 45, \"monthName\": \"Nov\", \"fwi\": 37.50416679382325},  \n",
    "      { \"week\": 46, \"monthName\": \"Nov\", \"fwi\": 29.76080322265625},  \n",
    "      { \"week\": 47, \"monthName\": \"Nov\", \"fwi\": 36.063685607910124},  \n",
    "      { \"week\": 48, \"monthName\": \"Nov\", \"fwi\": 34.42437210083008},  \n",
    "      { \"week\": 49, \"monthName\": \"Dec\", \"fwi\": 32.008924865722626},  \n",
    "      { \"week\": 50, \"monthName\": \"Dec\", \"fwi\": 33.579549407958986},  \n",
    "      { \"week\": 51, \"monthName\": \"Dec\", \"fwi\": 31.927024841308594},  \n",
    "      { \"week\": 52, \"monthName\": \"Dec\", \"fwi\": 34.5278169631958},  \n",
    "      { \"week\": 53, \"monthName\": \"Dec\", \"fwi\": 31.089004516601562}  \n",
    "\n",
    "]\n",
    "\n",
    "# convert fwi list to dataframe, fwi_df\n",
    "fwi_df = pd.DataFrame(fwi)\n",
    "\n",
    "# create output CSV of fwi_df for plotting\n",
    "fwi_output_df = pd.DataFrame({\n",
    "    'week': fwi_df['week'],\n",
    "    'monthName': fwi_df['monthName'],\n",
    "    'fwi': fwi_df['fwi'].round(2),  # round the count to 2 decimal places\n",
    "})\n",
    "\n",
    "# save fwi_output_df for fwi data to CSV\n",
    "fwi_output_df.to_csv('data/processed/fwi.csv', index=False)\n",
    "\n",
    "print(\"csv file created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows of the output:\n",
      "   week monthName    fwi\n",
      "0     1       Jan  36.04\n",
      "1     2       Jan  28.35\n",
      "2     3       Jan  34.49\n",
      "3     4       Jan  35.16\n",
      "4     5       Feb  41.22\n",
      "5     6       Feb  42.92\n",
      "6     7       Feb  40.36\n",
      "7     8       Feb  35.13\n",
      "8     9       Feb  43.73\n",
      "9    10       Mar  55.63\n",
      "\n",
      "Total number of records: 53\n",
      "Month names: ['Jan' 'Feb' 'Mar' 'Apr' 'May' 'Jun' 'Jul' 'Aug' 'Sep' 'Oct' 'Nov' 'Dec']\n",
      "fwi values: [36.04 28.35 34.49 35.16 41.22 42.92 40.36 35.13 43.73 55.63 51.96 48.64\n",
      " 48.46 42.53 48.99 47.95 59.69 53.26 67.04 66.29 63.51 57.6  66.98 75.75\n",
      " 80.3  90.7  75.26 95.59 82.07 81.9  81.7  81.58 65.29 67.3  64.21 69.21\n",
      " 59.38 50.01 40.39 48.37 43.82 37.04 50.05 47.38 37.5  29.76 36.06 34.42\n",
      " 32.01 33.58 31.93 34.53 31.09]\n"
     ]
    }
   ],
   "source": [
    "# fwi data check\n",
    "print(\"\\nFirst 10 rows of the output:\")\n",
    "print(fwi_output_df.head(10))\n",
    "\n",
    "# summary statistics\n",
    "print(f\"\\nTotal number of records: {len(fwi_output_df)}\")\n",
    "print(f\"Month names: {fwi_output_df['monthName'].unique()}\")\n",
    "print(f\"fwi values: {fwi_output_df['fwi'].unique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
